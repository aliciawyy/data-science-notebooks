{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import skew, boxcox\n",
    "from IPython.core.pylabtools import figsize\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "\n",
    "from os import path\n",
    "to_filename = lambda name: path.join(\"..\", \"data\", \"allstate\", name +\".csv\")\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: train (188318, 131), test (125546, 130)\n",
      "   cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10   ...        cont6  \\\n",
      "id                                                      ...                \n",
      "1     A    B    A    B    A    A    A    A    B     A   ...     0.718367   \n",
      "2     A    B    A    A    A    A    A    A    B     B   ...     0.438917   \n",
      "\n",
      "       cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
      "id                                                                      \n",
      "1   0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
      "2   0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
      "\n",
      "      cont14     loss  \n",
      "id                     \n",
      "1   0.714843  2213.18  \n",
      "2   0.304496  1283.60  \n",
      "\n",
      "[2 rows x 131 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(to_filename(\"train\"), index_col=0)\n",
    "test = pd.read_csv(to_filename(\"test\"), index_col=0)\n",
    "print(\"shape: train {}, test {}\".format(train.shape, test.shape))\n",
    "print(train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = np.log(train.loss)\n",
    "\n",
    "def restore_pred(y):\n",
    "    return np.exp(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Categorical columns:', ['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18', 'cat19', 'cat20', 'cat21', 'cat22', 'cat23', 'cat24', 'cat25', 'cat26', 'cat27', 'cat28', 'cat29', 'cat30', 'cat31', 'cat32', 'cat33', 'cat34', 'cat35', 'cat36', 'cat37', 'cat38', 'cat39', 'cat40', 'cat41', 'cat42', 'cat43', 'cat44', 'cat45', 'cat46', 'cat47', 'cat48', 'cat49', 'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56', 'cat57', 'cat58', 'cat59', 'cat60', 'cat61', 'cat62', 'cat63', 'cat64', 'cat65', 'cat66', 'cat67', 'cat68', 'cat69', 'cat70', 'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76', 'cat77', 'cat78', 'cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84', 'cat85', 'cat86', 'cat87', 'cat88', 'cat89', 'cat90', 'cat91', 'cat92', 'cat93', 'cat94', 'cat95', 'cat96', 'cat97', 'cat98', 'cat99', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104', 'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat110', 'cat111', 'cat112', 'cat113', 'cat114', 'cat115', 'cat116'])\n"
     ]
    }
   ],
   "source": [
    "cat_features = [col for col in train.columns if col.startswith(\"cat\")]\n",
    "print(\"Categorical columns:\", cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorical features preprocessing\n",
    "# Method 1: Encoding categorical features into int\n",
    "for col in cat_features:\n",
    "    encd = preprocessing.LabelEncoder()\n",
    "    encd.fit(train[col].value_counts().index.union(test[col].value_counts().index))\n",
    "    train[col] = encd.transform(train[col])\n",
    "    test[col] = encd.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method 2: Using ordered features for categorical features\n",
    "col = cat_features[0]\n",
    "test_col = train[col][:10].copy()\n",
    "for col in cat_features:\n",
    "    key_map = response.groupby(train[col]).mean().to_dict()\n",
    "    train[col] = train[col].replace(key_map)\n",
    "    for k in set(test[col].value_counts().index).difference(key_map.keys()):\n",
    "        key_map[k] = np.NAN\n",
    "    test[col] = test[col].replace(key_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocess numerical features\n",
    "num_features = [col for col in train.columns if col.startswith(\"cont\")]\n",
    "print(\"Numerical columns:\", num_features)\n",
    "\n",
    "selected_fea = list(num_features)\n",
    "selected_fea.remove(\"cont1\")\n",
    "selected_fea.remove(\"cont2\")\n",
    "selected_fea.remove(\"cont13\")\n",
    "selected_fea.remove(\"cont14\")\n",
    "print(selected_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train[selected_fea].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method 1: Standard Scaler\n",
    "for col in selected_fea:\n",
    "    sc = preprocessing.StandardScaler()\n",
    "    # sc.fit(pd.concat([train[[col]], test[[col]]]))\n",
    "    sc.fit(train[[col]])\n",
    "    train[col] = sc.transform(train[[col]])\n",
    "    test[col] = sc.transform(test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train[selected_fea].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# study the skewness in the numerical features\n",
    "# skewed_feats = pd.concat([train[num_features], test[num_features]]).skew()\n",
    "skewed_feats = train[selected_fea].skew()\n",
    "print(\"Skew in numeric features:\", skewed_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_skewed_feats = skewed_feats[skewed_feats > 0.25].index\n",
    "print(\"selected skew feats\", selected_skewed_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method 2: Box-Cox transformation when numerical feature skewed\n",
    "for feat in selected_skewed_feats:\n",
    "    train[feat], lam = boxcox(train[feat] + 1.)\n",
    "    test[feat], lam = boxcox(test[feat] + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train.drop(\"loss\", 1), response)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'objective':\"reg:linear\", 'silent': True, 'max_depth': 7, 'min_child_weight': 1,\n",
    "          'colsample_bytree': .7, \"subsample\": .95, 'eta': 0.1, 'eval_metric':'mae',# \"n_estimators\": 20,\n",
    "          \"gamma\": 0.55, \"lambda\": 1., \"silent\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    test-mae-mean  test-mae-std  train-mae-mean  train-mae-std\n",
      "0        6.466958      0.003119        6.466966       0.001000\n",
      "1        5.820601      0.003090        5.820514       0.000885\n",
      "2        5.238770      0.003016        5.238672       0.000804\n",
      "3        4.715121      0.003085        4.715063       0.000751\n",
      "4        4.243845      0.003164        4.243813       0.000664\n",
      "5        3.819759      0.003106        3.819721       0.000621\n",
      "6        3.438110      0.003145        3.438035       0.000539\n",
      "7        3.094651      0.003193        3.094550       0.000506\n",
      "8        2.785572      0.003216        2.785474       0.000451\n",
      "9        2.507509      0.003259        2.507439       0.000370\n",
      "10       2.257462      0.003260        2.257330       0.000304\n",
      "11       2.032702      0.003212        2.032519       0.000286\n",
      "12       1.830921      0.003225        1.830647       0.000278\n",
      "13       1.649882      0.003266        1.649576       0.000198\n",
      "14       1.487857      0.003333        1.487416       0.000254\n",
      "15       1.343204      0.003435        1.342660       0.000227\n",
      "16       1.214657      0.003477        1.213891       0.000234\n",
      "17       1.101147      0.003349        1.100074       0.000217\n",
      "18       1.001423      0.003223        1.000056       0.000169\n",
      "19       0.914520      0.003055        0.912861       0.000117\n",
      "20       0.839325      0.002930        0.837322       0.000127\n",
      "21       0.774689      0.002677        0.772323       0.000087\n",
      "22       0.719393      0.002311        0.716681       0.000131\n",
      "23       0.672516      0.002047        0.669377       0.000143\n",
      "24       0.632941      0.001755        0.629357       0.000220\n",
      "25       0.599584      0.001611        0.595636       0.000183\n",
      "26       0.571508      0.001309        0.567195       0.000211\n",
      "27       0.548115      0.001041        0.543461       0.000244\n",
      "28       0.528502      0.000920        0.523502       0.000301\n",
      "29       0.512105      0.000910        0.506769       0.000433\n",
      "30       0.498512      0.000764        0.492866       0.000459\n",
      "31       0.487078      0.000652        0.481166       0.000413\n",
      "32       0.477554      0.000628        0.471359       0.000371\n",
      "33       0.469638      0.000446        0.463160       0.000487\n",
      "34       0.462978      0.000515        0.456206       0.000374\n",
      "35       0.457456      0.000413        0.450426       0.000315\n",
      "36       0.452674      0.000603        0.445381       0.000418\n",
      "37       0.448828      0.000502        0.441288       0.000379\n",
      "38       0.445499      0.000490        0.437706       0.000362\n",
      "39       0.442657      0.000422        0.434617       0.000431\n",
      "40       0.440239      0.000428        0.431989       0.000379\n",
      "41       0.438192      0.000411        0.429715       0.000391\n",
      "42       0.436481      0.000318        0.427789       0.000396\n",
      "43       0.434931      0.000234        0.425996       0.000353\n",
      "44       0.433644      0.000216        0.424492       0.000426\n",
      "45       0.432457      0.000200        0.423091       0.000336\n",
      "46       0.431520      0.000199        0.421968       0.000345\n",
      "47       0.430566      0.000198        0.420823       0.000194\n",
      "48       0.429763      0.000279        0.419857       0.000234\n",
      "49       0.429062      0.000242        0.418959       0.000120\n"
     ]
    }
   ],
   "source": [
    "cvresult = xgb.cv(params, dtrain, nfold=4, num_boost_round=50, early_stopping_rounds=20)\n",
    "print(cvresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:6.46769\teval-mae:6.46361\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mae:5.82114\teval-mae:5.81685\n",
      "[2]\ttrain-mae:5.23921\teval-mae:5.23479\n",
      "[3]\ttrain-mae:4.7154\teval-mae:4.71071\n",
      "[4]\ttrain-mae:4.24416\teval-mae:4.23934\n",
      "[5]\ttrain-mae:3.81994\teval-mae:3.81497\n",
      "[6]\ttrain-mae:3.43817\teval-mae:3.43315\n",
      "[7]\ttrain-mae:3.09465\teval-mae:3.08955\n",
      "[8]\ttrain-mae:2.78553\teval-mae:2.78032\n",
      "[9]\ttrain-mae:2.50742\teval-mae:2.50219\n",
      "[10]\ttrain-mae:2.25735\teval-mae:2.25214\n",
      "[11]\ttrain-mae:2.0325\teval-mae:2.02715\n",
      "[12]\ttrain-mae:1.83058\teval-mae:1.82507\n",
      "[13]\ttrain-mae:1.64947\teval-mae:1.64387\n",
      "[14]\ttrain-mae:1.4873\teval-mae:1.48166\n",
      "[15]\ttrain-mae:1.34249\teval-mae:1.33693\n",
      "[16]\ttrain-mae:1.21372\teval-mae:1.20851\n",
      "[17]\ttrain-mae:1.09978\teval-mae:1.09502\n",
      "[18]\ttrain-mae:0.999791\teval-mae:0.99561\n",
      "[19]\ttrain-mae:0.912561\teval-mae:0.909059\n",
      "[20]\ttrain-mae:0.83693\teval-mae:0.834041\n",
      "[21]\ttrain-mae:0.771915\teval-mae:0.769462\n",
      "[22]\ttrain-mae:0.716264\teval-mae:0.714277\n",
      "[23]\ttrain-mae:0.668982\teval-mae:0.667561\n",
      "[24]\ttrain-mae:0.629114\teval-mae:0.628209\n",
      "[25]\ttrain-mae:0.595609\teval-mae:0.59523\n",
      "[26]\ttrain-mae:0.567368\teval-mae:0.567582\n",
      "[27]\ttrain-mae:0.543377\teval-mae:0.544058\n",
      "[28]\ttrain-mae:0.52354\teval-mae:0.524764\n",
      "[29]\ttrain-mae:0.506694\teval-mae:0.508479\n",
      "[30]\ttrain-mae:0.492649\teval-mae:0.494882\n",
      "[31]\ttrain-mae:0.480881\teval-mae:0.483487\n",
      "[32]\ttrain-mae:0.471173\teval-mae:0.474251\n",
      "[33]\ttrain-mae:0.462927\teval-mae:0.46657\n",
      "[34]\ttrain-mae:0.456097\teval-mae:0.460142\n",
      "[35]\ttrain-mae:0.450324\teval-mae:0.454837\n",
      "[36]\ttrain-mae:0.445364\teval-mae:0.450298\n",
      "[37]\ttrain-mae:0.441111\teval-mae:0.446437\n",
      "[38]\ttrain-mae:0.437673\teval-mae:0.443392\n",
      "[39]\ttrain-mae:0.43465\teval-mae:0.44071\n",
      "[40]\ttrain-mae:0.431817\teval-mae:0.438211\n",
      "[41]\ttrain-mae:0.429723\teval-mae:0.436507\n",
      "[42]\ttrain-mae:0.42786\teval-mae:0.434998\n",
      "[43]\ttrain-mae:0.426153\teval-mae:0.433631\n",
      "[44]\ttrain-mae:0.424692\teval-mae:0.432476\n",
      "[45]\ttrain-mae:0.423473\teval-mae:0.431541\n",
      "[46]\ttrain-mae:0.422324\teval-mae:0.430683\n",
      "[47]\ttrain-mae:0.421304\teval-mae:0.429904\n",
      "[48]\ttrain-mae:0.420369\teval-mae:0.429177\n",
      "[49]\ttrain-mae:0.419538\teval-mae:0.42859\n",
      "[50]\ttrain-mae:0.418534\teval-mae:0.427776\n",
      "[51]\ttrain-mae:0.417891\teval-mae:0.427385\n",
      "[52]\ttrain-mae:0.417163\teval-mae:0.426854\n",
      "[53]\ttrain-mae:0.416508\teval-mae:0.426361\n",
      "[54]\ttrain-mae:0.415916\teval-mae:0.425912\n",
      "[55]\ttrain-mae:0.415342\teval-mae:0.425536\n",
      "[56]\ttrain-mae:0.414871\teval-mae:0.425274\n",
      "[57]\ttrain-mae:0.414406\teval-mae:0.425058\n",
      "[58]\ttrain-mae:0.413946\teval-mae:0.424748\n",
      "[59]\ttrain-mae:0.413571\teval-mae:0.424545\n",
      "[60]\ttrain-mae:0.413117\teval-mae:0.424314\n",
      "[61]\ttrain-mae:0.412739\teval-mae:0.424078\n",
      "[62]\ttrain-mae:0.412244\teval-mae:0.423753\n",
      "[63]\ttrain-mae:0.41186\teval-mae:0.423551\n",
      "[64]\ttrain-mae:0.411535\teval-mae:0.423406\n",
      "[65]\ttrain-mae:0.411129\teval-mae:0.423187\n",
      "[66]\ttrain-mae:0.410774\teval-mae:0.422969\n",
      "[67]\ttrain-mae:0.410459\teval-mae:0.422819\n",
      "[68]\ttrain-mae:0.410015\teval-mae:0.422614\n",
      "[69]\ttrain-mae:0.409663\teval-mae:0.422383\n",
      "[70]\ttrain-mae:0.409365\teval-mae:0.422214\n",
      "[71]\ttrain-mae:0.409092\teval-mae:0.422063\n",
      "[72]\ttrain-mae:0.40863\teval-mae:0.421785\n",
      "[73]\ttrain-mae:0.408372\teval-mae:0.421671\n",
      "[74]\ttrain-mae:0.40803\teval-mae:0.421542\n",
      "[75]\ttrain-mae:0.40778\teval-mae:0.421439\n",
      "[76]\ttrain-mae:0.407524\teval-mae:0.421343\n",
      "[77]\ttrain-mae:0.407231\teval-mae:0.421219\n",
      "[78]\ttrain-mae:0.406963\teval-mae:0.421136\n",
      "[79]\ttrain-mae:0.406711\teval-mae:0.421007\n",
      "[80]\ttrain-mae:0.406366\teval-mae:0.420842\n",
      "[81]\ttrain-mae:0.406112\teval-mae:0.420715\n",
      "[82]\ttrain-mae:0.405889\teval-mae:0.420681\n",
      "[83]\ttrain-mae:0.405675\teval-mae:0.420575\n",
      "[84]\ttrain-mae:0.405399\teval-mae:0.420416\n",
      "[85]\ttrain-mae:0.405095\teval-mae:0.420205\n",
      "[86]\ttrain-mae:0.404852\teval-mae:0.420067\n",
      "[87]\ttrain-mae:0.404534\teval-mae:0.419962\n",
      "[88]\ttrain-mae:0.404411\teval-mae:0.419886\n",
      "[89]\ttrain-mae:0.404193\teval-mae:0.419804\n",
      "[90]\ttrain-mae:0.40394\teval-mae:0.419714\n",
      "[91]\ttrain-mae:0.403803\teval-mae:0.419663\n",
      "[92]\ttrain-mae:0.403556\teval-mae:0.419582\n",
      "[93]\ttrain-mae:0.403382\teval-mae:0.419526\n",
      "[94]\ttrain-mae:0.403054\teval-mae:0.419359\n",
      "[95]\ttrain-mae:0.40284\teval-mae:0.419219\n",
      "[96]\ttrain-mae:0.402685\teval-mae:0.419188\n",
      "[97]\ttrain-mae:0.402513\teval-mae:0.419139\n",
      "[98]\ttrain-mae:0.402266\teval-mae:0.419036\n",
      "[99]\ttrain-mae:0.402166\teval-mae:0.418977\n",
      "[100]\ttrain-mae:0.401985\teval-mae:0.418903\n",
      "[101]\ttrain-mae:0.401742\teval-mae:0.418817\n",
      "[102]\ttrain-mae:0.401509\teval-mae:0.418735\n",
      "[103]\ttrain-mae:0.401257\teval-mae:0.418598\n",
      "[104]\ttrain-mae:0.401101\teval-mae:0.418534\n",
      "[105]\ttrain-mae:0.400993\teval-mae:0.418496\n",
      "[106]\ttrain-mae:0.400821\teval-mae:0.418497\n",
      "[107]\ttrain-mae:0.400581\teval-mae:0.418429\n",
      "[108]\ttrain-mae:0.40041\teval-mae:0.418375\n",
      "[109]\ttrain-mae:0.400197\teval-mae:0.418301\n",
      "[110]\ttrain-mae:0.400084\teval-mae:0.418276\n",
      "[111]\ttrain-mae:0.399843\teval-mae:0.41818\n",
      "[112]\ttrain-mae:0.399652\teval-mae:0.418132\n",
      "[113]\ttrain-mae:0.399393\teval-mae:0.417984\n",
      "[114]\ttrain-mae:0.399156\teval-mae:0.417922\n",
      "[115]\ttrain-mae:0.399005\teval-mae:0.417873\n",
      "[116]\ttrain-mae:0.398943\teval-mae:0.417872\n",
      "[117]\ttrain-mae:0.39876\teval-mae:0.417826\n",
      "[118]\ttrain-mae:0.39865\teval-mae:0.417833\n",
      "[119]\ttrain-mae:0.398525\teval-mae:0.417865\n",
      "[120]\ttrain-mae:0.398392\teval-mae:0.417853\n",
      "[121]\ttrain-mae:0.398302\teval-mae:0.417824\n",
      "[122]\ttrain-mae:0.398169\teval-mae:0.417781\n",
      "[123]\ttrain-mae:0.397967\teval-mae:0.417757\n",
      "[124]\ttrain-mae:0.397826\teval-mae:0.417745\n",
      "[125]\ttrain-mae:0.397725\teval-mae:0.417721\n",
      "[126]\ttrain-mae:0.397474\teval-mae:0.417625\n",
      "[127]\ttrain-mae:0.397297\teval-mae:0.4176\n",
      "[128]\ttrain-mae:0.39712\teval-mae:0.417501\n",
      "[129]\ttrain-mae:0.397041\teval-mae:0.417484\n",
      "[130]\ttrain-mae:0.396903\teval-mae:0.417427\n",
      "[131]\ttrain-mae:0.396777\teval-mae:0.417379\n",
      "[132]\ttrain-mae:0.396681\teval-mae:0.417346\n",
      "[133]\ttrain-mae:0.396459\teval-mae:0.417327\n",
      "[134]\ttrain-mae:0.396315\teval-mae:0.417316\n",
      "[135]\ttrain-mae:0.396116\teval-mae:0.417292\n",
      "[136]\ttrain-mae:0.395965\teval-mae:0.417221\n",
      "[137]\ttrain-mae:0.395774\teval-mae:0.417206\n",
      "[138]\ttrain-mae:0.395611\teval-mae:0.417167\n",
      "[139]\ttrain-mae:0.395478\teval-mae:0.417168\n",
      "[140]\ttrain-mae:0.395386\teval-mae:0.417159\n",
      "[141]\ttrain-mae:0.395293\teval-mae:0.417146\n",
      "[142]\ttrain-mae:0.395158\teval-mae:0.417111\n",
      "[143]\ttrain-mae:0.395067\teval-mae:0.417139\n",
      "[144]\ttrain-mae:0.394958\teval-mae:0.417084\n",
      "[145]\ttrain-mae:0.39483\teval-mae:0.417055\n",
      "[146]\ttrain-mae:0.394739\teval-mae:0.417023\n",
      "[147]\ttrain-mae:0.394537\teval-mae:0.41695\n",
      "[148]\ttrain-mae:0.394406\teval-mae:0.416913\n",
      "[149]\ttrain-mae:0.394255\teval-mae:0.416882\n",
      "[150]\ttrain-mae:0.394118\teval-mae:0.41687\n",
      "[151]\ttrain-mae:0.393975\teval-mae:0.416854\n",
      "[152]\ttrain-mae:0.393875\teval-mae:0.416854\n",
      "[153]\ttrain-mae:0.393707\teval-mae:0.41682\n",
      "[154]\ttrain-mae:0.393507\teval-mae:0.416764\n",
      "[155]\ttrain-mae:0.393367\teval-mae:0.41672\n",
      "[156]\ttrain-mae:0.393226\teval-mae:0.416693\n",
      "[157]\ttrain-mae:0.393139\teval-mae:0.416683\n",
      "[158]\ttrain-mae:0.393027\teval-mae:0.416673\n",
      "[159]\ttrain-mae:0.392949\teval-mae:0.416669\n",
      "[160]\ttrain-mae:0.392923\teval-mae:0.416668\n",
      "[161]\ttrain-mae:0.392761\teval-mae:0.416611\n",
      "[162]\ttrain-mae:0.392673\teval-mae:0.416593\n",
      "[163]\ttrain-mae:0.39253\teval-mae:0.416573\n",
      "[164]\ttrain-mae:0.392475\teval-mae:0.416563\n",
      "[165]\ttrain-mae:0.39234\teval-mae:0.416573\n",
      "[166]\ttrain-mae:0.392259\teval-mae:0.416538\n",
      "[167]\ttrain-mae:0.392097\teval-mae:0.416504\n",
      "[168]\ttrain-mae:0.392008\teval-mae:0.416492\n",
      "[169]\ttrain-mae:0.391947\teval-mae:0.416487\n",
      "[170]\ttrain-mae:0.39186\teval-mae:0.416471\n",
      "[171]\ttrain-mae:0.391805\teval-mae:0.416476\n",
      "[172]\ttrain-mae:0.391686\teval-mae:0.416444\n",
      "[173]\ttrain-mae:0.391588\teval-mae:0.416416\n",
      "[174]\ttrain-mae:0.391463\teval-mae:0.416386\n",
      "[175]\ttrain-mae:0.391307\teval-mae:0.416359\n",
      "[176]\ttrain-mae:0.391273\teval-mae:0.416361\n",
      "[177]\ttrain-mae:0.391124\teval-mae:0.416336\n",
      "[178]\ttrain-mae:0.391056\teval-mae:0.416337\n",
      "[179]\ttrain-mae:0.390962\teval-mae:0.416331\n",
      "[180]\ttrain-mae:0.390855\teval-mae:0.416317\n",
      "[181]\ttrain-mae:0.39068\teval-mae:0.416303\n",
      "[182]\ttrain-mae:0.390505\teval-mae:0.416255\n",
      "[183]\ttrain-mae:0.390434\teval-mae:0.41624\n",
      "[184]\ttrain-mae:0.390321\teval-mae:0.416219\n",
      "[185]\ttrain-mae:0.390155\teval-mae:0.416201\n",
      "[186]\ttrain-mae:0.39014\teval-mae:0.416204\n",
      "[187]\ttrain-mae:0.390054\teval-mae:0.416185\n",
      "[188]\ttrain-mae:0.389996\teval-mae:0.416165\n",
      "[189]\ttrain-mae:0.389853\teval-mae:0.416161\n",
      "[190]\ttrain-mae:0.389769\teval-mae:0.416163\n",
      "[191]\ttrain-mae:0.389628\teval-mae:0.416147\n",
      "[192]\ttrain-mae:0.389559\teval-mae:0.416148\n",
      "[193]\ttrain-mae:0.389411\teval-mae:0.416126\n",
      "[194]\ttrain-mae:0.389228\teval-mae:0.416135\n",
      "[195]\ttrain-mae:0.389146\teval-mae:0.416112\n",
      "[196]\ttrain-mae:0.388988\teval-mae:0.416096\n",
      "[197]\ttrain-mae:0.388956\teval-mae:0.416095\n",
      "[198]\ttrain-mae:0.388847\teval-mae:0.416082\n",
      "[199]\ttrain-mae:0.388721\teval-mae:0.416062\n",
      "[200]\ttrain-mae:0.388573\teval-mae:0.416021\n",
      "[201]\ttrain-mae:0.388499\teval-mae:0.416013\n",
      "[202]\ttrain-mae:0.388312\teval-mae:0.415936\n",
      "[203]\ttrain-mae:0.388061\teval-mae:0.415868\n",
      "[204]\ttrain-mae:0.387941\teval-mae:0.415873\n",
      "[205]\ttrain-mae:0.387756\teval-mae:0.415849\n",
      "[206]\ttrain-mae:0.387661\teval-mae:0.415831\n",
      "[207]\ttrain-mae:0.38759\teval-mae:0.415826\n",
      "[208]\ttrain-mae:0.387493\teval-mae:0.415843\n",
      "[209]\ttrain-mae:0.387302\teval-mae:0.415785\n",
      "[210]\ttrain-mae:0.38722\teval-mae:0.41577\n",
      "[211]\ttrain-mae:0.387139\teval-mae:0.415778\n",
      "[212]\ttrain-mae:0.386997\teval-mae:0.415776\n",
      "[213]\ttrain-mae:0.386779\teval-mae:0.415723\n",
      "[214]\ttrain-mae:0.386633\teval-mae:0.415727\n",
      "[215]\ttrain-mae:0.386505\teval-mae:0.415736\n",
      "[216]\ttrain-mae:0.386412\teval-mae:0.415754\n",
      "[217]\ttrain-mae:0.386345\teval-mae:0.415745\n",
      "[218]\ttrain-mae:0.386229\teval-mae:0.415734\n",
      "[219]\ttrain-mae:0.386109\teval-mae:0.415702\n",
      "[220]\ttrain-mae:0.386025\teval-mae:0.415702\n",
      "[221]\ttrain-mae:0.385866\teval-mae:0.415702\n",
      "[222]\ttrain-mae:0.385734\teval-mae:0.415725\n",
      "[223]\ttrain-mae:0.385631\teval-mae:0.415734\n",
      "[224]\ttrain-mae:0.385463\teval-mae:0.415703\n",
      "[225]\ttrain-mae:0.385335\teval-mae:0.415656\n",
      "[226]\ttrain-mae:0.385308\teval-mae:0.415663\n",
      "[227]\ttrain-mae:0.385202\teval-mae:0.415637\n",
      "[228]\ttrain-mae:0.384949\teval-mae:0.415516\n",
      "[229]\ttrain-mae:0.384802\teval-mae:0.415519\n",
      "[230]\ttrain-mae:0.384739\teval-mae:0.415515\n",
      "[231]\ttrain-mae:0.384651\teval-mae:0.415508\n",
      "[232]\ttrain-mae:0.38453\teval-mae:0.415509\n",
      "[233]\ttrain-mae:0.384354\teval-mae:0.41548\n",
      "[234]\ttrain-mae:0.384269\teval-mae:0.415473\n",
      "[235]\ttrain-mae:0.384107\teval-mae:0.415463\n",
      "[236]\ttrain-mae:0.384028\teval-mae:0.415451\n",
      "[237]\ttrain-mae:0.383895\teval-mae:0.41546\n",
      "[238]\ttrain-mae:0.383811\teval-mae:0.415448\n",
      "[239]\ttrain-mae:0.383676\teval-mae:0.415443\n",
      "[240]\ttrain-mae:0.383651\teval-mae:0.415444\n",
      "[241]\ttrain-mae:0.383572\teval-mae:0.415425\n",
      "[242]\ttrain-mae:0.38351\teval-mae:0.415415\n",
      "[243]\ttrain-mae:0.383259\teval-mae:0.415371\n",
      "[244]\ttrain-mae:0.38313\teval-mae:0.415347\n",
      "[245]\ttrain-mae:0.382989\teval-mae:0.415307\n",
      "[246]\ttrain-mae:0.382893\teval-mae:0.415325\n",
      "[247]\ttrain-mae:0.382785\teval-mae:0.415333\n",
      "[248]\ttrain-mae:0.382665\teval-mae:0.415333\n",
      "[249]\ttrain-mae:0.382567\teval-mae:0.415331\n",
      "[250]\ttrain-mae:0.38246\teval-mae:0.415346\n",
      "[251]\ttrain-mae:0.382413\teval-mae:0.415354\n",
      "[252]\ttrain-mae:0.382358\teval-mae:0.415338\n",
      "[253]\ttrain-mae:0.382318\teval-mae:0.415339\n",
      "[254]\ttrain-mae:0.382184\teval-mae:0.415303\n",
      "[255]\ttrain-mae:0.382101\teval-mae:0.4153\n",
      "[256]\ttrain-mae:0.382012\teval-mae:0.415316\n",
      "[257]\ttrain-mae:0.381898\teval-mae:0.415367\n",
      "[258]\ttrain-mae:0.38179\teval-mae:0.415385\n",
      "[259]\ttrain-mae:0.381645\teval-mae:0.415325\n",
      "[260]\ttrain-mae:0.381571\teval-mae:0.415323\n",
      "[261]\ttrain-mae:0.381505\teval-mae:0.415328\n",
      "[262]\ttrain-mae:0.381481\teval-mae:0.415322\n",
      "[263]\ttrain-mae:0.381351\teval-mae:0.415327\n",
      "[264]\ttrain-mae:0.381334\teval-mae:0.41532\n",
      "[265]\ttrain-mae:0.381166\teval-mae:0.415273\n",
      "[266]\ttrain-mae:0.381099\teval-mae:0.415275\n",
      "[267]\ttrain-mae:0.380967\teval-mae:0.415248\n",
      "[268]\ttrain-mae:0.380914\teval-mae:0.415253\n",
      "[269]\ttrain-mae:0.380839\teval-mae:0.415272\n",
      "[270]\ttrain-mae:0.380748\teval-mae:0.415301\n",
      "[271]\ttrain-mae:0.380652\teval-mae:0.415301\n",
      "[272]\ttrain-mae:0.380497\teval-mae:0.415298\n",
      "[273]\ttrain-mae:0.380411\teval-mae:0.415294\n",
      "[274]\ttrain-mae:0.38036\teval-mae:0.415312\n",
      "[275]\ttrain-mae:0.380292\teval-mae:0.415318\n",
      "[276]\ttrain-mae:0.3802\teval-mae:0.415315\n",
      "[277]\ttrain-mae:0.380084\teval-mae:0.41531\n",
      "[278]\ttrain-mae:0.380054\teval-mae:0.415306\n",
      "[279]\ttrain-mae:0.379996\teval-mae:0.415296\n",
      "[280]\ttrain-mae:0.379885\teval-mae:0.415291\n",
      "[281]\ttrain-mae:0.379757\teval-mae:0.415309\n",
      "[282]\ttrain-mae:0.379575\teval-mae:0.415242\n",
      "[283]\ttrain-mae:0.379525\teval-mae:0.415231\n",
      "[284]\ttrain-mae:0.379445\teval-mae:0.415231\n",
      "[285]\ttrain-mae:0.379349\teval-mae:0.415255\n",
      "[286]\ttrain-mae:0.379307\teval-mae:0.415255\n",
      "[287]\ttrain-mae:0.379253\teval-mae:0.415234\n",
      "[288]\ttrain-mae:0.379139\teval-mae:0.415219\n",
      "[289]\ttrain-mae:0.37907\teval-mae:0.41522\n",
      "[290]\ttrain-mae:0.378963\teval-mae:0.415221\n",
      "[291]\ttrain-mae:0.378795\teval-mae:0.415207\n",
      "[292]\ttrain-mae:0.378741\teval-mae:0.41519\n",
      "[293]\ttrain-mae:0.378659\teval-mae:0.415189\n",
      "[294]\ttrain-mae:0.378553\teval-mae:0.415187\n",
      "[295]\ttrain-mae:0.378387\teval-mae:0.415171\n",
      "[296]\ttrain-mae:0.378362\teval-mae:0.415166\n",
      "[297]\ttrain-mae:0.378219\teval-mae:0.415181\n",
      "[298]\ttrain-mae:0.378121\teval-mae:0.415186\n",
      "[299]\ttrain-mae:0.378091\teval-mae:0.415187\n",
      "[300]\ttrain-mae:0.377972\teval-mae:0.415197\n",
      "[301]\ttrain-mae:0.377808\teval-mae:0.415168\n",
      "[302]\ttrain-mae:0.377779\teval-mae:0.41517\n",
      "[303]\ttrain-mae:0.377712\teval-mae:0.415157\n",
      "[304]\ttrain-mae:0.377603\teval-mae:0.415163\n",
      "[305]\ttrain-mae:0.37759\teval-mae:0.415173\n",
      "[306]\ttrain-mae:0.377491\teval-mae:0.415159\n",
      "[307]\ttrain-mae:0.377353\teval-mae:0.415151\n",
      "[308]\ttrain-mae:0.377249\teval-mae:0.415161\n",
      "[309]\ttrain-mae:0.377135\teval-mae:0.415159\n",
      "[310]\ttrain-mae:0.377101\teval-mae:0.415173\n",
      "[311]\ttrain-mae:0.376973\teval-mae:0.415179\n",
      "[312]\ttrain-mae:0.376852\teval-mae:0.415174\n",
      "[313]\ttrain-mae:0.376703\teval-mae:0.415193\n",
      "[314]\ttrain-mae:0.376598\teval-mae:0.41522\n",
      "[315]\ttrain-mae:0.37654\teval-mae:0.415212\n",
      "[316]\ttrain-mae:0.376394\teval-mae:0.41519\n",
      "[317]\ttrain-mae:0.376352\teval-mae:0.415189\n",
      "[318]\ttrain-mae:0.376271\teval-mae:0.415194\n",
      "[319]\ttrain-mae:0.376195\teval-mae:0.415205\n",
      "[320]\ttrain-mae:0.376145\teval-mae:0.415211\n",
      "[321]\ttrain-mae:0.375996\teval-mae:0.415189\n",
      "[322]\ttrain-mae:0.375904\teval-mae:0.415192\n",
      "[323]\ttrain-mae:0.375804\teval-mae:0.415169\n",
      "[324]\ttrain-mae:0.375706\teval-mae:0.415173\n",
      "[325]\ttrain-mae:0.375624\teval-mae:0.415169\n",
      "[326]\ttrain-mae:0.375508\teval-mae:0.415178\n",
      "[327]\ttrain-mae:0.375367\teval-mae:0.415151\n",
      "Stopping. Best iteration:\n",
      "[307]\ttrain-mae:0.377353\teval-mae:0.415151\n",
      "\n",
      "('best ntree limit', 0, 308)\n",
      "('mae for part train', 0, 1021.7472476565287)\n",
      "('mae for part test', 0, 1145.5284094213973)\n",
      "('mae for all train', 0, 1046.5037429289507)\n",
      "[0]\ttrain-mae:6.46655\teval-mae:6.46905\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mae:5.82016\teval-mae:5.82275\n",
      "[2]\ttrain-mae:5.23834\teval-mae:5.2409\n",
      "[3]\ttrain-mae:4.71475\teval-mae:4.71723\n",
      "[4]\ttrain-mae:4.2435\teval-mae:4.24591\n",
      "[5]\ttrain-mae:3.81947\teval-mae:3.822\n",
      "[6]\ttrain-mae:3.43778\teval-mae:3.44026\n",
      "[7]\ttrain-mae:3.09433\teval-mae:3.09681\n",
      "[8]\ttrain-mae:2.78521\teval-mae:2.78763\n",
      "[9]\ttrain-mae:2.50712\teval-mae:2.50956\n",
      "[10]\ttrain-mae:2.25704\teval-mae:2.25949\n",
      "[11]\ttrain-mae:2.03228\teval-mae:2.03481\n",
      "[12]\ttrain-mae:1.83029\teval-mae:1.83304\n",
      "[13]\ttrain-mae:1.6492\teval-mae:1.65209\n",
      "[14]\ttrain-mae:1.48702\teval-mae:1.48992\n",
      "[15]\ttrain-mae:1.3422\teval-mae:1.34522\n",
      "[16]\ttrain-mae:1.21351\teval-mae:1.21654\n",
      "[17]\ttrain-mae:1.09976\teval-mae:1.10294\n",
      "[18]\ttrain-mae:0.999755\teval-mae:1.00325\n",
      "[19]\ttrain-mae:0.912546\teval-mae:0.916159\n",
      "[20]\ttrain-mae:0.836904\teval-mae:0.840586\n",
      "[21]\ttrain-mae:0.771998\teval-mae:0.775767\n",
      "[22]\ttrain-mae:0.716403\teval-mae:0.720152\n",
      "[23]\ttrain-mae:0.668979\teval-mae:0.672754\n",
      "[24]\ttrain-mae:0.629036\teval-mae:0.632991\n",
      "[25]\ttrain-mae:0.59532\teval-mae:0.599384\n",
      "[26]\ttrain-mae:0.566915\teval-mae:0.571141\n",
      "[27]\ttrain-mae:0.543293\teval-mae:0.547697\n",
      "[28]\ttrain-mae:0.523496\teval-mae:0.528021\n",
      "[29]\ttrain-mae:0.506848\teval-mae:0.511468\n",
      "[30]\ttrain-mae:0.492827\teval-mae:0.497545\n",
      "[31]\ttrain-mae:0.481263\teval-mae:0.486102\n",
      "[32]\ttrain-mae:0.471591\teval-mae:0.476602\n",
      "[33]\ttrain-mae:0.46327\teval-mae:0.468483\n",
      "[34]\ttrain-mae:0.455987\teval-mae:0.461412\n",
      "[35]\ttrain-mae:0.449986\teval-mae:0.45568\n",
      "[36]\ttrain-mae:0.445216\teval-mae:0.451107\n",
      "[37]\ttrain-mae:0.440895\teval-mae:0.446928\n",
      "[38]\ttrain-mae:0.437412\teval-mae:0.44352\n",
      "[39]\ttrain-mae:0.434511\teval-mae:0.44062\n",
      "[40]\ttrain-mae:0.431868\teval-mae:0.438103\n",
      "[41]\ttrain-mae:0.429716\teval-mae:0.436081\n",
      "[42]\ttrain-mae:0.427767\teval-mae:0.434234\n",
      "[43]\ttrain-mae:0.426246\teval-mae:0.432777\n",
      "[44]\ttrain-mae:0.424783\teval-mae:0.431432\n",
      "[45]\ttrain-mae:0.423531\teval-mae:0.430313\n",
      "[46]\ttrain-mae:0.422373\teval-mae:0.429308\n",
      "[47]\ttrain-mae:0.421362\teval-mae:0.428414\n",
      "[48]\ttrain-mae:0.420389\teval-mae:0.427583\n",
      "[49]\ttrain-mae:0.419514\teval-mae:0.426877\n",
      "[50]\ttrain-mae:0.418743\teval-mae:0.426245\n",
      "[51]\ttrain-mae:0.417979\teval-mae:0.425654\n",
      "[52]\ttrain-mae:0.417373\teval-mae:0.425197\n",
      "[53]\ttrain-mae:0.416622\teval-mae:0.424587\n",
      "[54]\ttrain-mae:0.415966\teval-mae:0.424054\n",
      "[55]\ttrain-mae:0.415505\teval-mae:0.423729\n",
      "[56]\ttrain-mae:0.415041\teval-mae:0.423411\n",
      "[57]\ttrain-mae:0.414609\teval-mae:0.423151\n",
      "[58]\ttrain-mae:0.414104\teval-mae:0.422764\n",
      "[59]\ttrain-mae:0.413559\teval-mae:0.422376\n",
      "[60]\ttrain-mae:0.413128\teval-mae:0.422073\n",
      "[61]\ttrain-mae:0.412712\teval-mae:0.42178\n",
      "[62]\ttrain-mae:0.412373\teval-mae:0.421594\n",
      "[63]\ttrain-mae:0.412102\teval-mae:0.421481\n",
      "[64]\ttrain-mae:0.411755\teval-mae:0.421294\n",
      "[65]\ttrain-mae:0.411443\teval-mae:0.421108\n",
      "[66]\ttrain-mae:0.411043\teval-mae:0.420836\n",
      "[67]\ttrain-mae:0.410761\teval-mae:0.420657\n",
      "[68]\ttrain-mae:0.410423\teval-mae:0.420442\n",
      "[69]\ttrain-mae:0.410078\teval-mae:0.420267\n",
      "[70]\ttrain-mae:0.409718\teval-mae:0.420013\n",
      "[71]\ttrain-mae:0.409427\teval-mae:0.419844\n",
      "[72]\ttrain-mae:0.409147\teval-mae:0.419677\n",
      "[73]\ttrain-mae:0.408824\teval-mae:0.419495\n",
      "[74]\ttrain-mae:0.408678\teval-mae:0.419429\n",
      "[75]\ttrain-mae:0.408367\teval-mae:0.419343\n",
      "[76]\ttrain-mae:0.408151\teval-mae:0.419305\n",
      "[77]\ttrain-mae:0.407827\teval-mae:0.419179\n",
      "[78]\ttrain-mae:0.407583\teval-mae:0.419075\n",
      "[79]\ttrain-mae:0.407359\teval-mae:0.418988\n",
      "[80]\ttrain-mae:0.407179\teval-mae:0.418911\n",
      "[81]\ttrain-mae:0.406789\teval-mae:0.418701\n",
      "[82]\ttrain-mae:0.406537\teval-mae:0.418593\n",
      "[83]\ttrain-mae:0.406285\teval-mae:0.418502\n",
      "[84]\ttrain-mae:0.405997\teval-mae:0.418335\n",
      "[85]\ttrain-mae:0.40579\teval-mae:0.418281\n",
      "[86]\ttrain-mae:0.405562\teval-mae:0.418198\n",
      "[87]\ttrain-mae:0.405317\teval-mae:0.418062\n",
      "[88]\ttrain-mae:0.405153\teval-mae:0.418017\n",
      "[89]\ttrain-mae:0.404948\teval-mae:0.417937\n",
      "[90]\ttrain-mae:0.404751\teval-mae:0.417864\n",
      "[91]\ttrain-mae:0.404521\teval-mae:0.417755\n",
      "[92]\ttrain-mae:0.404268\teval-mae:0.417619\n",
      "[93]\ttrain-mae:0.40409\teval-mae:0.417554\n",
      "[94]\ttrain-mae:0.403868\teval-mae:0.417446\n",
      "[95]\ttrain-mae:0.403661\teval-mae:0.417386\n",
      "[96]\ttrain-mae:0.403516\teval-mae:0.417321\n",
      "[97]\ttrain-mae:0.403366\teval-mae:0.417253\n",
      "[98]\ttrain-mae:0.403224\teval-mae:0.417227\n",
      "[99]\ttrain-mae:0.403103\teval-mae:0.417207\n",
      "[100]\ttrain-mae:0.402866\teval-mae:0.41715\n",
      "[101]\ttrain-mae:0.402658\teval-mae:0.417117\n",
      "[102]\ttrain-mae:0.402377\teval-mae:0.416964\n",
      "[103]\ttrain-mae:0.402231\teval-mae:0.416912\n",
      "[104]\ttrain-mae:0.401991\teval-mae:0.416841\n",
      "[105]\ttrain-mae:0.401829\teval-mae:0.416823\n",
      "[106]\ttrain-mae:0.401551\teval-mae:0.416737\n",
      "[107]\ttrain-mae:0.401446\teval-mae:0.416727\n",
      "[108]\ttrain-mae:0.401215\teval-mae:0.416672\n",
      "[109]\ttrain-mae:0.400959\teval-mae:0.416574\n",
      "[110]\ttrain-mae:0.400747\teval-mae:0.416465\n",
      "[111]\ttrain-mae:0.400607\teval-mae:0.416371\n",
      "[112]\ttrain-mae:0.400432\teval-mae:0.416301\n",
      "[113]\ttrain-mae:0.400213\teval-mae:0.416238\n",
      "[114]\ttrain-mae:0.400121\teval-mae:0.416225\n",
      "[115]\ttrain-mae:0.399972\teval-mae:0.416167\n",
      "[116]\ttrain-mae:0.399873\teval-mae:0.416169\n",
      "[117]\ttrain-mae:0.399639\teval-mae:0.416068\n",
      "[118]\ttrain-mae:0.399466\teval-mae:0.416049\n",
      "[119]\ttrain-mae:0.399366\teval-mae:0.416018\n",
      "[120]\ttrain-mae:0.399143\teval-mae:0.415936\n",
      "[121]\ttrain-mae:0.399016\teval-mae:0.415926\n",
      "[122]\ttrain-mae:0.398854\teval-mae:0.415892\n",
      "[123]\ttrain-mae:0.398682\teval-mae:0.415862\n",
      "[124]\ttrain-mae:0.398575\teval-mae:0.415856\n",
      "[125]\ttrain-mae:0.398434\teval-mae:0.415827\n",
      "[126]\ttrain-mae:0.398193\teval-mae:0.415725\n",
      "[127]\ttrain-mae:0.398012\teval-mae:0.415678\n",
      "[128]\ttrain-mae:0.397928\teval-mae:0.415642\n",
      "[129]\ttrain-mae:0.397808\teval-mae:0.415635\n",
      "[130]\ttrain-mae:0.397712\teval-mae:0.415621\n",
      "[131]\ttrain-mae:0.397485\teval-mae:0.415551\n",
      "[132]\ttrain-mae:0.397315\teval-mae:0.41552\n",
      "[133]\ttrain-mae:0.397188\teval-mae:0.415516\n",
      "[134]\ttrain-mae:0.397022\teval-mae:0.415489\n",
      "[135]\ttrain-mae:0.396778\teval-mae:0.415473\n",
      "[136]\ttrain-mae:0.396563\teval-mae:0.415414\n",
      "[137]\ttrain-mae:0.396344\teval-mae:0.415348\n",
      "[138]\ttrain-mae:0.396116\teval-mae:0.415274\n",
      "[139]\ttrain-mae:0.396006\teval-mae:0.415253\n",
      "[140]\ttrain-mae:0.395961\teval-mae:0.41524\n",
      "[141]\ttrain-mae:0.395717\teval-mae:0.415165\n",
      "[142]\ttrain-mae:0.395552\teval-mae:0.415103\n",
      "[143]\ttrain-mae:0.395446\teval-mae:0.415108\n",
      "[144]\ttrain-mae:0.395396\teval-mae:0.415102\n",
      "[145]\ttrain-mae:0.395182\teval-mae:0.415064\n",
      "[146]\ttrain-mae:0.394973\teval-mae:0.414996\n",
      "[147]\ttrain-mae:0.394789\teval-mae:0.414946\n",
      "[148]\ttrain-mae:0.394645\teval-mae:0.41494\n",
      "[149]\ttrain-mae:0.394444\teval-mae:0.414907\n",
      "[150]\ttrain-mae:0.3944\teval-mae:0.414897\n",
      "[151]\ttrain-mae:0.39428\teval-mae:0.414884\n",
      "[152]\ttrain-mae:0.394092\teval-mae:0.414866\n",
      "[153]\ttrain-mae:0.393924\teval-mae:0.414865\n",
      "[154]\ttrain-mae:0.393825\teval-mae:0.41485\n",
      "[155]\ttrain-mae:0.393734\teval-mae:0.414841\n",
      "[156]\ttrain-mae:0.393638\teval-mae:0.41483\n",
      "[157]\ttrain-mae:0.393531\teval-mae:0.414801\n",
      "[158]\ttrain-mae:0.393308\teval-mae:0.414726\n",
      "[159]\ttrain-mae:0.39323\teval-mae:0.414716\n",
      "[160]\ttrain-mae:0.393133\teval-mae:0.414676\n",
      "[161]\ttrain-mae:0.392982\teval-mae:0.414637\n",
      "[162]\ttrain-mae:0.392897\teval-mae:0.414636\n",
      "[163]\ttrain-mae:0.392725\teval-mae:0.414613\n",
      "[164]\ttrain-mae:0.392572\teval-mae:0.414606\n",
      "[165]\ttrain-mae:0.39242\teval-mae:0.414616\n",
      "[166]\ttrain-mae:0.392385\teval-mae:0.414626\n",
      "[167]\ttrain-mae:0.392264\teval-mae:0.414637\n",
      "[168]\ttrain-mae:0.392172\teval-mae:0.414605\n",
      "[169]\ttrain-mae:0.392035\teval-mae:0.414599\n",
      "[170]\ttrain-mae:0.392018\teval-mae:0.414591\n",
      "[171]\ttrain-mae:0.391953\teval-mae:0.414578\n",
      "[172]\ttrain-mae:0.391832\teval-mae:0.414561\n",
      "[173]\ttrain-mae:0.39179\teval-mae:0.414563\n",
      "[174]\ttrain-mae:0.391655\teval-mae:0.414556\n",
      "[175]\ttrain-mae:0.391533\teval-mae:0.414516\n",
      "[176]\ttrain-mae:0.391318\teval-mae:0.414487\n",
      "[177]\ttrain-mae:0.391253\teval-mae:0.414478\n",
      "[178]\ttrain-mae:0.391064\teval-mae:0.41443\n",
      "[179]\ttrain-mae:0.390987\teval-mae:0.41443\n",
      "[180]\ttrain-mae:0.390785\teval-mae:0.414411\n",
      "[181]\ttrain-mae:0.390567\teval-mae:0.414374\n",
      "[182]\ttrain-mae:0.390449\teval-mae:0.414362\n",
      "[183]\ttrain-mae:0.390372\teval-mae:0.414357\n",
      "[184]\ttrain-mae:0.390257\teval-mae:0.414331\n",
      "[185]\ttrain-mae:0.390215\teval-mae:0.414334\n",
      "[186]\ttrain-mae:0.390097\teval-mae:0.414319\n",
      "[187]\ttrain-mae:0.389944\teval-mae:0.414272\n",
      "[188]\ttrain-mae:0.389867\teval-mae:0.414283\n",
      "[189]\ttrain-mae:0.38969\teval-mae:0.414274\n",
      "[190]\ttrain-mae:0.389591\teval-mae:0.414267\n",
      "[191]\ttrain-mae:0.389465\teval-mae:0.414269\n",
      "[192]\ttrain-mae:0.389284\teval-mae:0.414239\n",
      "[193]\ttrain-mae:0.389155\teval-mae:0.414202\n",
      "[194]\ttrain-mae:0.389101\teval-mae:0.414199\n",
      "[195]\ttrain-mae:0.388946\teval-mae:0.414202\n",
      "[196]\ttrain-mae:0.388764\teval-mae:0.414199\n",
      "[197]\ttrain-mae:0.388657\teval-mae:0.4142\n",
      "[198]\ttrain-mae:0.38862\teval-mae:0.414196\n",
      "[199]\ttrain-mae:0.38851\teval-mae:0.414217\n",
      "[200]\ttrain-mae:0.388373\teval-mae:0.414204\n",
      "[201]\ttrain-mae:0.388237\teval-mae:0.414212\n",
      "[202]\ttrain-mae:0.388158\teval-mae:0.414198\n",
      "[203]\ttrain-mae:0.388013\teval-mae:0.414149\n",
      "[204]\ttrain-mae:0.387913\teval-mae:0.414142\n",
      "[205]\ttrain-mae:0.387821\teval-mae:0.414137\n",
      "[206]\ttrain-mae:0.387687\teval-mae:0.414147\n",
      "[207]\ttrain-mae:0.387551\teval-mae:0.414134\n",
      "[208]\ttrain-mae:0.387465\teval-mae:0.414098\n",
      "[209]\ttrain-mae:0.387349\teval-mae:0.414092\n",
      "[210]\ttrain-mae:0.387282\teval-mae:0.414064\n",
      "[211]\ttrain-mae:0.387243\teval-mae:0.414056\n",
      "[212]\ttrain-mae:0.387168\teval-mae:0.414069\n",
      "[213]\ttrain-mae:0.387014\teval-mae:0.414052\n",
      "[214]\ttrain-mae:0.386884\teval-mae:0.414031\n",
      "[215]\ttrain-mae:0.38681\teval-mae:0.414024\n",
      "[216]\ttrain-mae:0.386642\teval-mae:0.413974\n",
      "[217]\ttrain-mae:0.386521\teval-mae:0.413966\n",
      "[218]\ttrain-mae:0.386383\teval-mae:0.413956\n",
      "[219]\ttrain-mae:0.38629\teval-mae:0.413939\n",
      "[220]\ttrain-mae:0.386185\teval-mae:0.413934\n",
      "[221]\ttrain-mae:0.386008\teval-mae:0.413929\n",
      "[222]\ttrain-mae:0.385939\teval-mae:0.413933\n",
      "[223]\ttrain-mae:0.385873\teval-mae:0.413922\n",
      "[224]\ttrain-mae:0.385759\teval-mae:0.413935\n",
      "[225]\ttrain-mae:0.385608\teval-mae:0.41391\n",
      "[226]\ttrain-mae:0.385555\teval-mae:0.413905\n",
      "[227]\ttrain-mae:0.385421\teval-mae:0.413897\n",
      "[228]\ttrain-mae:0.38535\teval-mae:0.413889\n",
      "[229]\ttrain-mae:0.385225\teval-mae:0.413878\n",
      "[230]\ttrain-mae:0.38513\teval-mae:0.413873\n",
      "[231]\ttrain-mae:0.384988\teval-mae:0.413808\n",
      "[232]\ttrain-mae:0.384879\teval-mae:0.413772\n",
      "[233]\ttrain-mae:0.384791\teval-mae:0.413776\n",
      "[234]\ttrain-mae:0.384711\teval-mae:0.413774\n",
      "[235]\ttrain-mae:0.384695\teval-mae:0.413772\n",
      "[236]\ttrain-mae:0.384653\teval-mae:0.413773\n",
      "[237]\ttrain-mae:0.384589\teval-mae:0.413769\n",
      "[238]\ttrain-mae:0.384478\teval-mae:0.413775\n",
      "[239]\ttrain-mae:0.384421\teval-mae:0.41376\n",
      "[240]\ttrain-mae:0.384283\teval-mae:0.413739\n",
      "[241]\ttrain-mae:0.384141\teval-mae:0.413726\n",
      "[242]\ttrain-mae:0.383938\teval-mae:0.413709\n",
      "[243]\ttrain-mae:0.383758\teval-mae:0.413652\n",
      "[244]\ttrain-mae:0.383646\teval-mae:0.413644\n",
      "[245]\ttrain-mae:0.383526\teval-mae:0.413625\n",
      "[246]\ttrain-mae:0.383356\teval-mae:0.413615\n",
      "[247]\ttrain-mae:0.383169\teval-mae:0.413597\n",
      "[248]\ttrain-mae:0.383093\teval-mae:0.413588\n",
      "[249]\ttrain-mae:0.382974\teval-mae:0.413583\n",
      "[250]\ttrain-mae:0.382907\teval-mae:0.413568\n",
      "[251]\ttrain-mae:0.382874\teval-mae:0.413567\n",
      "[252]\ttrain-mae:0.382776\teval-mae:0.413551\n",
      "[253]\ttrain-mae:0.382628\teval-mae:0.413514\n",
      "[254]\ttrain-mae:0.382534\teval-mae:0.413508\n",
      "[255]\ttrain-mae:0.382387\teval-mae:0.413504\n",
      "[256]\ttrain-mae:0.382243\teval-mae:0.413499\n",
      "[257]\ttrain-mae:0.382197\teval-mae:0.413491\n",
      "[258]\ttrain-mae:0.382152\teval-mae:0.413484\n",
      "[259]\ttrain-mae:0.382019\teval-mae:0.413492\n",
      "[260]\ttrain-mae:0.381864\teval-mae:0.41349\n",
      "[261]\ttrain-mae:0.381737\teval-mae:0.41351\n",
      "[262]\ttrain-mae:0.381612\teval-mae:0.413493\n",
      "[263]\ttrain-mae:0.381516\teval-mae:0.413477\n",
      "[264]\ttrain-mae:0.381476\teval-mae:0.413497\n",
      "[265]\ttrain-mae:0.381352\teval-mae:0.413465\n",
      "[266]\ttrain-mae:0.381278\teval-mae:0.41347\n",
      "[267]\ttrain-mae:0.381225\teval-mae:0.413469\n",
      "[268]\ttrain-mae:0.381122\teval-mae:0.413473\n",
      "[269]\ttrain-mae:0.381033\teval-mae:0.413456\n",
      "[270]\ttrain-mae:0.380983\teval-mae:0.413441\n",
      "[271]\ttrain-mae:0.380821\teval-mae:0.413412\n",
      "[272]\ttrain-mae:0.380764\teval-mae:0.413416\n",
      "[273]\ttrain-mae:0.380596\teval-mae:0.413428\n",
      "[274]\ttrain-mae:0.380533\teval-mae:0.413425\n",
      "[275]\ttrain-mae:0.380464\teval-mae:0.41342\n",
      "[276]\ttrain-mae:0.380362\teval-mae:0.41339\n",
      "[277]\ttrain-mae:0.380297\teval-mae:0.413392\n",
      "[278]\ttrain-mae:0.380161\teval-mae:0.413393\n",
      "[279]\ttrain-mae:0.380052\teval-mae:0.413431\n",
      "[280]\ttrain-mae:0.379939\teval-mae:0.413436\n",
      "[281]\ttrain-mae:0.379846\teval-mae:0.413437\n",
      "[282]\ttrain-mae:0.379698\teval-mae:0.413442\n",
      "[283]\ttrain-mae:0.379605\teval-mae:0.413465\n",
      "[284]\ttrain-mae:0.379462\teval-mae:0.413483\n",
      "[285]\ttrain-mae:0.379406\teval-mae:0.413484\n",
      "[286]\ttrain-mae:0.379328\teval-mae:0.413491\n",
      "[287]\ttrain-mae:0.379193\teval-mae:0.413496\n",
      "[288]\ttrain-mae:0.379057\teval-mae:0.413492\n",
      "[289]\ttrain-mae:0.378955\teval-mae:0.4135\n",
      "[290]\ttrain-mae:0.378916\teval-mae:0.413494\n",
      "[291]\ttrain-mae:0.378837\teval-mae:0.413493\n",
      "[292]\ttrain-mae:0.378791\teval-mae:0.413503\n",
      "[293]\ttrain-mae:0.378677\teval-mae:0.413502\n",
      "[294]\ttrain-mae:0.378561\teval-mae:0.413446\n",
      "[295]\ttrain-mae:0.37853\teval-mae:0.413447\n",
      "[296]\ttrain-mae:0.378463\teval-mae:0.413454\n",
      "Stopping. Best iteration:\n",
      "[276]\ttrain-mae:0.380362\teval-mae:0.41339\n",
      "\n",
      "('best ntree limit', 1, 277)\n",
      "('mae for part train', 1, 1030.7118758736344)\n",
      "('mae for part test', 1, 1141.0188953628476)\n",
      "('mae for all train', 1, 1052.7735140709478)\n",
      "[0]\ttrain-mae:6.46669\teval-mae:6.46886\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mae:5.82021\teval-mae:5.82279\n",
      "[2]\ttrain-mae:5.23838\teval-mae:5.24129\n",
      "[3]\ttrain-mae:4.71475\teval-mae:4.718\n",
      "[4]\ttrain-mae:4.24342\teval-mae:4.24682\n",
      "[5]\ttrain-mae:3.81929\teval-mae:3.82288\n",
      "[6]\ttrain-mae:3.43755\teval-mae:3.44114\n",
      "[7]\ttrain-mae:3.09412\teval-mae:3.09785\n",
      "[8]\ttrain-mae:2.78511\teval-mae:2.78898\n",
      "[9]\ttrain-mae:2.507\teval-mae:2.51115\n",
      "[10]\ttrain-mae:2.2569\teval-mae:2.26129\n",
      "[11]\ttrain-mae:2.03205\teval-mae:2.0367\n",
      "[12]\ttrain-mae:1.83014\teval-mae:1.83487\n",
      "[13]\ttrain-mae:1.64905\teval-mae:1.65401\n",
      "[14]\ttrain-mae:1.48697\teval-mae:1.49213\n",
      "[15]\ttrain-mae:1.34225\teval-mae:1.3476\n",
      "[16]\ttrain-mae:1.21358\teval-mae:1.21912\n",
      "[17]\ttrain-mae:1.0998\teval-mae:1.1055\n",
      "[18]\ttrain-mae:0.999883\teval-mae:1.00574\n",
      "[19]\ttrain-mae:0.912747\teval-mae:0.918616\n",
      "[20]\ttrain-mae:0.837123\teval-mae:0.843347\n",
      "[21]\ttrain-mae:0.772163\teval-mae:0.77884\n",
      "[22]\ttrain-mae:0.716311\teval-mae:0.723443\n",
      "[23]\ttrain-mae:0.669031\teval-mae:0.67657\n",
      "[24]\ttrain-mae:0.629122\teval-mae:0.637025\n",
      "[25]\ttrain-mae:0.595336\teval-mae:0.603536\n",
      "[26]\ttrain-mae:0.566772\teval-mae:0.575333\n",
      "[27]\ttrain-mae:0.543105\teval-mae:0.552015\n",
      "[28]\ttrain-mae:0.523313\teval-mae:0.53262\n",
      "[29]\ttrain-mae:0.506544\teval-mae:0.516107\n",
      "[30]\ttrain-mae:0.492505\teval-mae:0.502354\n",
      "[31]\ttrain-mae:0.480845\teval-mae:0.490896\n",
      "[32]\ttrain-mae:0.471202\teval-mae:0.481458\n",
      "[33]\ttrain-mae:0.462897\teval-mae:0.473375\n",
      "[34]\ttrain-mae:0.455741\teval-mae:0.466445\n",
      "[35]\ttrain-mae:0.450071\teval-mae:0.460833\n",
      "[36]\ttrain-mae:0.445103\teval-mae:0.455966\n",
      "[37]\ttrain-mae:0.441071\teval-mae:0.452092\n",
      "[38]\ttrain-mae:0.437561\teval-mae:0.448748\n",
      "[39]\ttrain-mae:0.434573\teval-mae:0.445946\n",
      "[40]\ttrain-mae:0.431968\teval-mae:0.443529\n",
      "[41]\ttrain-mae:0.429756\teval-mae:0.441539\n",
      "[42]\ttrain-mae:0.427784\teval-mae:0.439723\n",
      "[43]\ttrain-mae:0.426066\teval-mae:0.438133\n",
      "[44]\ttrain-mae:0.424612\teval-mae:0.436835\n",
      "[45]\ttrain-mae:0.423304\teval-mae:0.435667\n",
      "[46]\ttrain-mae:0.422049\teval-mae:0.434612\n",
      "[47]\ttrain-mae:0.420722\teval-mae:0.433497\n",
      "[48]\ttrain-mae:0.419791\teval-mae:0.43271\n",
      "[49]\ttrain-mae:0.418929\teval-mae:0.43205\n",
      "[50]\ttrain-mae:0.418197\teval-mae:0.431476\n",
      "[51]\ttrain-mae:0.417564\teval-mae:0.430988\n",
      "[52]\ttrain-mae:0.416632\teval-mae:0.430231\n",
      "[53]\ttrain-mae:0.415974\teval-mae:0.429719\n",
      "[54]\ttrain-mae:0.415457\teval-mae:0.429372\n",
      "[55]\ttrain-mae:0.414572\teval-mae:0.428683\n",
      "[56]\ttrain-mae:0.414106\teval-mae:0.428399\n",
      "[57]\ttrain-mae:0.413305\teval-mae:0.427754\n",
      "[58]\ttrain-mae:0.412841\teval-mae:0.427472\n",
      "[59]\ttrain-mae:0.412488\teval-mae:0.427281\n",
      "[60]\ttrain-mae:0.412085\teval-mae:0.427078\n",
      "[61]\ttrain-mae:0.41164\teval-mae:0.426775\n",
      "[62]\ttrain-mae:0.411234\teval-mae:0.42652\n",
      "[63]\ttrain-mae:0.41089\teval-mae:0.42628\n",
      "[64]\ttrain-mae:0.410572\teval-mae:0.426062\n",
      "[65]\ttrain-mae:0.41028\teval-mae:0.425963\n",
      "[66]\ttrain-mae:0.409935\teval-mae:0.425804\n",
      "[67]\ttrain-mae:0.409645\teval-mae:0.425712\n",
      "[68]\ttrain-mae:0.4093\teval-mae:0.425472\n",
      "[69]\ttrain-mae:0.409021\teval-mae:0.42532\n",
      "[70]\ttrain-mae:0.408718\teval-mae:0.425148\n",
      "[71]\ttrain-mae:0.408453\teval-mae:0.425002\n",
      "[72]\ttrain-mae:0.408194\teval-mae:0.424861\n",
      "[73]\ttrain-mae:0.407949\teval-mae:0.424763\n",
      "[74]\ttrain-mae:0.407701\teval-mae:0.424633\n",
      "[75]\ttrain-mae:0.407451\teval-mae:0.424549\n",
      "[76]\ttrain-mae:0.407201\teval-mae:0.424459\n",
      "[77]\ttrain-mae:0.406935\teval-mae:0.424318\n",
      "[78]\ttrain-mae:0.406534\teval-mae:0.424081\n",
      "[79]\ttrain-mae:0.4063\teval-mae:0.423995\n",
      "[80]\ttrain-mae:0.405985\teval-mae:0.423784\n",
      "[81]\ttrain-mae:0.405777\teval-mae:0.423682\n",
      "[82]\ttrain-mae:0.405557\teval-mae:0.42365\n",
      "[83]\ttrain-mae:0.405312\teval-mae:0.423498\n",
      "[84]\ttrain-mae:0.405015\teval-mae:0.423395\n",
      "[85]\ttrain-mae:0.404721\teval-mae:0.423272\n",
      "[86]\ttrain-mae:0.404544\teval-mae:0.423208\n",
      "[87]\ttrain-mae:0.404351\teval-mae:0.423187\n",
      "[88]\ttrain-mae:0.404201\teval-mae:0.423129\n",
      "[89]\ttrain-mae:0.404036\teval-mae:0.423065\n",
      "[90]\ttrain-mae:0.403931\teval-mae:0.423078\n",
      "[91]\ttrain-mae:0.4038\teval-mae:0.423053\n",
      "[92]\ttrain-mae:0.40361\teval-mae:0.422942\n",
      "[93]\ttrain-mae:0.403473\teval-mae:0.422887\n",
      "[94]\ttrain-mae:0.40331\teval-mae:0.422881\n",
      "[95]\ttrain-mae:0.403165\teval-mae:0.422809\n",
      "[96]\ttrain-mae:0.403031\teval-mae:0.422774\n",
      "[97]\ttrain-mae:0.402856\teval-mae:0.422757\n",
      "[98]\ttrain-mae:0.402621\teval-mae:0.422638\n",
      "[99]\ttrain-mae:0.402439\teval-mae:0.422583\n",
      "[100]\ttrain-mae:0.402259\teval-mae:0.422572\n",
      "[101]\ttrain-mae:0.401963\teval-mae:0.422442\n",
      "[102]\ttrain-mae:0.401815\teval-mae:0.42239\n",
      "[103]\ttrain-mae:0.401603\teval-mae:0.422336\n",
      "[104]\ttrain-mae:0.40146\teval-mae:0.422246\n",
      "[105]\ttrain-mae:0.401252\teval-mae:0.422182\n",
      "[106]\ttrain-mae:0.401137\teval-mae:0.422164\n",
      "[107]\ttrain-mae:0.400996\teval-mae:0.422123\n",
      "[108]\ttrain-mae:0.400801\teval-mae:0.422046\n",
      "[109]\ttrain-mae:0.400575\teval-mae:0.42201\n",
      "[110]\ttrain-mae:0.400395\teval-mae:0.421977\n",
      "[111]\ttrain-mae:0.400195\teval-mae:0.421946\n",
      "[112]\ttrain-mae:0.400011\teval-mae:0.421918\n",
      "[113]\ttrain-mae:0.39986\teval-mae:0.421836\n",
      "[114]\ttrain-mae:0.399752\teval-mae:0.421804\n",
      "[115]\ttrain-mae:0.399693\teval-mae:0.421788\n",
      "[116]\ttrain-mae:0.3995\teval-mae:0.4217\n",
      "[117]\ttrain-mae:0.399249\teval-mae:0.421627\n",
      "[118]\ttrain-mae:0.399005\teval-mae:0.421557\n",
      "[119]\ttrain-mae:0.398871\teval-mae:0.421544\n",
      "[120]\ttrain-mae:0.398551\teval-mae:0.421488\n",
      "[121]\ttrain-mae:0.398335\teval-mae:0.421455\n",
      "[122]\ttrain-mae:0.398189\teval-mae:0.421423\n",
      "[123]\ttrain-mae:0.398055\teval-mae:0.421319\n",
      "[124]\ttrain-mae:0.397941\teval-mae:0.421341\n",
      "[125]\ttrain-mae:0.397794\teval-mae:0.421296\n",
      "[126]\ttrain-mae:0.397541\teval-mae:0.421229\n",
      "[127]\ttrain-mae:0.397463\teval-mae:0.421221\n",
      "[128]\ttrain-mae:0.397196\teval-mae:0.421072\n",
      "[129]\ttrain-mae:0.397108\teval-mae:0.421071\n",
      "[130]\ttrain-mae:0.396892\teval-mae:0.42103\n",
      "[131]\ttrain-mae:0.396734\teval-mae:0.420968\n",
      "[132]\ttrain-mae:0.396679\teval-mae:0.420958\n",
      "[133]\ttrain-mae:0.396565\teval-mae:0.420918\n",
      "[134]\ttrain-mae:0.396426\teval-mae:0.420915\n",
      "[135]\ttrain-mae:0.396326\teval-mae:0.42089\n",
      "[136]\ttrain-mae:0.39612\teval-mae:0.420805\n",
      "[137]\ttrain-mae:0.396001\teval-mae:0.42078\n",
      "[138]\ttrain-mae:0.395803\teval-mae:0.420758\n",
      "[139]\ttrain-mae:0.395654\teval-mae:0.420739\n",
      "[140]\ttrain-mae:0.395552\teval-mae:0.42071\n",
      "[141]\ttrain-mae:0.395391\teval-mae:0.420689\n",
      "[142]\ttrain-mae:0.395168\teval-mae:0.420605\n",
      "[143]\ttrain-mae:0.395086\teval-mae:0.420592\n",
      "[144]\ttrain-mae:0.395027\teval-mae:0.420595\n",
      "[145]\ttrain-mae:0.394846\teval-mae:0.420516\n",
      "[146]\ttrain-mae:0.394634\teval-mae:0.420454\n",
      "[147]\ttrain-mae:0.394461\teval-mae:0.420381\n",
      "[148]\ttrain-mae:0.394408\teval-mae:0.420371\n",
      "[149]\ttrain-mae:0.394307\teval-mae:0.42035\n",
      "[150]\ttrain-mae:0.394167\teval-mae:0.420293\n",
      "[151]\ttrain-mae:0.393968\teval-mae:0.420265\n",
      "[152]\ttrain-mae:0.393772\teval-mae:0.420218\n",
      "[153]\ttrain-mae:0.393661\teval-mae:0.420193\n",
      "[154]\ttrain-mae:0.393481\teval-mae:0.420156\n",
      "[155]\ttrain-mae:0.393333\teval-mae:0.420145\n",
      "[156]\ttrain-mae:0.393125\teval-mae:0.420063\n",
      "[157]\ttrain-mae:0.392919\teval-mae:0.420041\n",
      "[158]\ttrain-mae:0.392848\teval-mae:0.420045\n",
      "[159]\ttrain-mae:0.392747\teval-mae:0.420034\n",
      "[160]\ttrain-mae:0.392584\teval-mae:0.420007\n",
      "[161]\ttrain-mae:0.39254\teval-mae:0.42001\n",
      "[162]\ttrain-mae:0.392445\teval-mae:0.420014\n",
      "[163]\ttrain-mae:0.392388\teval-mae:0.419981\n",
      "[164]\ttrain-mae:0.392296\teval-mae:0.419968\n",
      "[165]\ttrain-mae:0.392107\teval-mae:0.419877\n",
      "[166]\ttrain-mae:0.391918\teval-mae:0.419788\n",
      "[167]\ttrain-mae:0.391763\teval-mae:0.419751\n",
      "[168]\ttrain-mae:0.391588\teval-mae:0.41974\n",
      "[169]\ttrain-mae:0.391512\teval-mae:0.419724\n",
      "[170]\ttrain-mae:0.391334\teval-mae:0.419726\n",
      "[171]\ttrain-mae:0.391154\teval-mae:0.419702\n",
      "[172]\ttrain-mae:0.391041\teval-mae:0.419698\n",
      "[173]\ttrain-mae:0.390939\teval-mae:0.419647\n",
      "[174]\ttrain-mae:0.390836\teval-mae:0.419633\n",
      "[175]\ttrain-mae:0.390773\teval-mae:0.419628\n",
      "[176]\ttrain-mae:0.390711\teval-mae:0.419616\n",
      "[177]\ttrain-mae:0.390541\teval-mae:0.419604\n",
      "[178]\ttrain-mae:0.390324\teval-mae:0.419578\n",
      "[179]\ttrain-mae:0.390219\teval-mae:0.419592\n",
      "[180]\ttrain-mae:0.390145\teval-mae:0.419566\n",
      "[181]\ttrain-mae:0.389978\teval-mae:0.419534\n",
      "[182]\ttrain-mae:0.389882\teval-mae:0.419538\n",
      "[183]\ttrain-mae:0.389778\teval-mae:0.419524\n",
      "[184]\ttrain-mae:0.389729\teval-mae:0.41952\n",
      "[185]\ttrain-mae:0.389555\teval-mae:0.419534\n",
      "[186]\ttrain-mae:0.389366\teval-mae:0.419468\n",
      "[187]\ttrain-mae:0.389261\teval-mae:0.419465\n",
      "[188]\ttrain-mae:0.389161\teval-mae:0.419465\n",
      "[189]\ttrain-mae:0.38904\teval-mae:0.419463\n",
      "[190]\ttrain-mae:0.388879\teval-mae:0.419434\n",
      "[191]\ttrain-mae:0.388776\teval-mae:0.419431\n",
      "[192]\ttrain-mae:0.388727\teval-mae:0.41943\n",
      "[193]\ttrain-mae:0.388584\teval-mae:0.41943\n",
      "[194]\ttrain-mae:0.388469\teval-mae:0.419427\n",
      "[195]\ttrain-mae:0.388329\teval-mae:0.41941\n",
      "[196]\ttrain-mae:0.388307\teval-mae:0.419409\n",
      "[197]\ttrain-mae:0.388174\teval-mae:0.419404\n",
      "[198]\ttrain-mae:0.388108\teval-mae:0.419418\n",
      "[199]\ttrain-mae:0.38801\teval-mae:0.419413\n",
      "[200]\ttrain-mae:0.387845\teval-mae:0.419405\n",
      "[201]\ttrain-mae:0.387719\teval-mae:0.4194\n",
      "[202]\ttrain-mae:0.387605\teval-mae:0.419374\n",
      "[203]\ttrain-mae:0.387464\teval-mae:0.419336\n",
      "[204]\ttrain-mae:0.387408\teval-mae:0.419319\n",
      "[205]\ttrain-mae:0.387312\teval-mae:0.419324\n",
      "[206]\ttrain-mae:0.387115\teval-mae:0.419267\n",
      "[207]\ttrain-mae:0.386975\teval-mae:0.419258\n",
      "[208]\ttrain-mae:0.386919\teval-mae:0.41926\n",
      "[209]\ttrain-mae:0.386766\teval-mae:0.419262\n",
      "[210]\ttrain-mae:0.386705\teval-mae:0.419251\n",
      "[211]\ttrain-mae:0.386571\teval-mae:0.419239\n",
      "[212]\ttrain-mae:0.386452\teval-mae:0.419245\n",
      "[213]\ttrain-mae:0.386365\teval-mae:0.419245\n",
      "[214]\ttrain-mae:0.386269\teval-mae:0.419217\n",
      "[215]\ttrain-mae:0.386153\teval-mae:0.419206\n",
      "[216]\ttrain-mae:0.386024\teval-mae:0.419185\n",
      "[217]\ttrain-mae:0.385961\teval-mae:0.419186\n",
      "[218]\ttrain-mae:0.385855\teval-mae:0.419175\n",
      "[219]\ttrain-mae:0.38575\teval-mae:0.41918\n",
      "[220]\ttrain-mae:0.385688\teval-mae:0.419178\n",
      "[221]\ttrain-mae:0.38565\teval-mae:0.419173\n",
      "[222]\ttrain-mae:0.385446\teval-mae:0.41909\n",
      "[223]\ttrain-mae:0.385287\teval-mae:0.419082\n",
      "[224]\ttrain-mae:0.385173\teval-mae:0.419085\n",
      "[225]\ttrain-mae:0.38509\teval-mae:0.419071\n",
      "[226]\ttrain-mae:0.384978\teval-mae:0.419075\n",
      "[227]\ttrain-mae:0.384906\teval-mae:0.419044\n",
      "[228]\ttrain-mae:0.384748\teval-mae:0.419016\n",
      "[229]\ttrain-mae:0.384581\teval-mae:0.418985\n",
      "[230]\ttrain-mae:0.384533\teval-mae:0.418997\n",
      "[231]\ttrain-mae:0.384401\teval-mae:0.418972\n",
      "[232]\ttrain-mae:0.384206\teval-mae:0.418941\n",
      "[233]\ttrain-mae:0.384104\teval-mae:0.418932\n",
      "[234]\ttrain-mae:0.384029\teval-mae:0.418919\n",
      "[235]\ttrain-mae:0.383898\teval-mae:0.418961\n",
      "[236]\ttrain-mae:0.383797\teval-mae:0.418954\n",
      "[237]\ttrain-mae:0.383734\teval-mae:0.418945\n",
      "[238]\ttrain-mae:0.383722\teval-mae:0.418946\n",
      "[239]\ttrain-mae:0.383532\teval-mae:0.418926\n",
      "[240]\ttrain-mae:0.383433\teval-mae:0.418904\n",
      "[241]\ttrain-mae:0.383319\teval-mae:0.418897\n",
      "[242]\ttrain-mae:0.383202\teval-mae:0.418896\n",
      "[243]\ttrain-mae:0.383036\teval-mae:0.418868\n",
      "[244]\ttrain-mae:0.382894\teval-mae:0.418874\n",
      "[245]\ttrain-mae:0.382723\teval-mae:0.418851\n",
      "[246]\ttrain-mae:0.382641\teval-mae:0.41882\n",
      "[247]\ttrain-mae:0.382503\teval-mae:0.418834\n",
      "[248]\ttrain-mae:0.382454\teval-mae:0.418827\n",
      "[249]\ttrain-mae:0.382444\teval-mae:0.418827\n",
      "[250]\ttrain-mae:0.382339\teval-mae:0.418817\n",
      "[251]\ttrain-mae:0.382218\teval-mae:0.418784\n",
      "[252]\ttrain-mae:0.382169\teval-mae:0.418752\n",
      "[253]\ttrain-mae:0.382045\teval-mae:0.418717\n",
      "[254]\ttrain-mae:0.382007\teval-mae:0.41873\n",
      "[255]\ttrain-mae:0.381897\teval-mae:0.418702\n",
      "[256]\ttrain-mae:0.381777\teval-mae:0.418705\n",
      "[257]\ttrain-mae:0.381623\teval-mae:0.418725\n",
      "[258]\ttrain-mae:0.381505\teval-mae:0.418722\n",
      "[259]\ttrain-mae:0.381444\teval-mae:0.418732\n",
      "[260]\ttrain-mae:0.381328\teval-mae:0.418735\n",
      "[261]\ttrain-mae:0.381212\teval-mae:0.418754\n",
      "[262]\ttrain-mae:0.38103\teval-mae:0.418746\n",
      "[263]\ttrain-mae:0.380969\teval-mae:0.418748\n",
      "[264]\ttrain-mae:0.380855\teval-mae:0.418742\n",
      "[265]\ttrain-mae:0.380764\teval-mae:0.418743\n",
      "[266]\ttrain-mae:0.380654\teval-mae:0.41873\n",
      "[267]\ttrain-mae:0.38054\teval-mae:0.418725\n",
      "[268]\ttrain-mae:0.380458\teval-mae:0.418716\n",
      "[269]\ttrain-mae:0.380424\teval-mae:0.41872\n",
      "[270]\ttrain-mae:0.380383\teval-mae:0.418726\n",
      "[271]\ttrain-mae:0.380246\teval-mae:0.418688\n",
      "[272]\ttrain-mae:0.380095\teval-mae:0.418663\n",
      "[273]\ttrain-mae:0.380055\teval-mae:0.418667\n",
      "[274]\ttrain-mae:0.379886\teval-mae:0.418644\n",
      "[275]\ttrain-mae:0.379799\teval-mae:0.418634\n",
      "[276]\ttrain-mae:0.379691\teval-mae:0.418648\n",
      "[277]\ttrain-mae:0.379644\teval-mae:0.418659\n",
      "[278]\ttrain-mae:0.379615\teval-mae:0.41866\n",
      "[279]\ttrain-mae:0.379459\teval-mae:0.418679\n",
      "[280]\ttrain-mae:0.379356\teval-mae:0.418685\n",
      "[281]\ttrain-mae:0.379234\teval-mae:0.418716\n",
      "[282]\ttrain-mae:0.379129\teval-mae:0.418725\n",
      "[283]\ttrain-mae:0.379017\teval-mae:0.418718\n",
      "[284]\ttrain-mae:0.37896\teval-mae:0.418715\n",
      "[285]\ttrain-mae:0.378842\teval-mae:0.418705\n",
      "[286]\ttrain-mae:0.378764\teval-mae:0.418685\n",
      "[287]\ttrain-mae:0.378647\teval-mae:0.418679\n",
      "[288]\ttrain-mae:0.378574\teval-mae:0.418699\n",
      "[289]\ttrain-mae:0.378484\teval-mae:0.418676\n",
      "[290]\ttrain-mae:0.378396\teval-mae:0.418685\n",
      "[291]\ttrain-mae:0.378348\teval-mae:0.418693\n",
      "[292]\ttrain-mae:0.378282\teval-mae:0.41869\n",
      "[293]\ttrain-mae:0.378231\teval-mae:0.41869\n",
      "[294]\ttrain-mae:0.378147\teval-mae:0.418717\n",
      "[295]\ttrain-mae:0.378035\teval-mae:0.418702\n",
      "Stopping. Best iteration:\n",
      "[275]\ttrain-mae:0.379799\teval-mae:0.418634\n",
      "\n",
      "('best ntree limit', 2, 276)\n",
      "('mae for part train', 2, 1027.7874574602413)\n",
      "('mae for part test', 2, 1158.11436592666)\n",
      "('mae for all train', 2, 1053.8531159765764)\n",
      "[0]\ttrain-mae:6.46703\teval-mae:6.46657\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mae:5.8206\teval-mae:5.81989\n",
      "[2]\ttrain-mae:5.23871\teval-mae:5.23808\n",
      "[3]\ttrain-mae:4.71503\teval-mae:4.71432\n",
      "[4]\ttrain-mae:4.24375\teval-mae:4.24291\n",
      "[5]\ttrain-mae:3.81961\teval-mae:3.81866\n",
      "[6]\ttrain-mae:3.4379\teval-mae:3.43687\n",
      "[7]\ttrain-mae:3.09439\teval-mae:3.0932\n",
      "[8]\ttrain-mae:2.78534\teval-mae:2.78396\n",
      "[9]\ttrain-mae:2.50728\teval-mae:2.50582\n",
      "[10]\ttrain-mae:2.25726\teval-mae:2.25575\n",
      "[11]\ttrain-mae:2.03241\teval-mae:2.03077\n",
      "[12]\ttrain-mae:1.83047\teval-mae:1.82896\n",
      "[13]\ttrain-mae:1.64937\teval-mae:1.6481\n",
      "[14]\ttrain-mae:1.48708\teval-mae:1.4864\n",
      "[15]\ttrain-mae:1.34227\teval-mae:1.34212\n",
      "[16]\ttrain-mae:1.21343\teval-mae:1.21365\n",
      "[17]\ttrain-mae:1.0996\teval-mae:1.10007\n",
      "[18]\ttrain-mae:0.999495\teval-mae:1.00033\n",
      "[19]\ttrain-mae:0.912224\teval-mae:0.913515\n",
      "[20]\ttrain-mae:0.83667\teval-mae:0.838456\n",
      "[21]\ttrain-mae:0.771773\teval-mae:0.774012\n",
      "[22]\ttrain-mae:0.715939\teval-mae:0.718763\n",
      "[23]\ttrain-mae:0.668681\teval-mae:0.672146\n",
      "[24]\ttrain-mae:0.628582\teval-mae:0.632755\n",
      "[25]\ttrain-mae:0.594753\teval-mae:0.599583\n",
      "[26]\ttrain-mae:0.566439\teval-mae:0.571809\n",
      "[27]\ttrain-mae:0.542689\teval-mae:0.548646\n",
      "[28]\ttrain-mae:0.52257\teval-mae:0.529079\n",
      "[29]\ttrain-mae:0.505892\teval-mae:0.512872\n",
      "[30]\ttrain-mae:0.491939\teval-mae:0.499256\n",
      "[31]\ttrain-mae:0.480126\teval-mae:0.487884\n",
      "[32]\ttrain-mae:0.470445\teval-mae:0.478521\n",
      "[33]\ttrain-mae:0.462232\teval-mae:0.470616\n",
      "[34]\ttrain-mae:0.455476\teval-mae:0.464098\n",
      "[35]\ttrain-mae:0.449675\teval-mae:0.458552\n",
      "[36]\ttrain-mae:0.444768\teval-mae:0.453827\n",
      "[37]\ttrain-mae:0.440764\teval-mae:0.450049\n",
      "[38]\ttrain-mae:0.437308\teval-mae:0.446876\n",
      "[39]\ttrain-mae:0.434221\teval-mae:0.443985\n",
      "[40]\ttrain-mae:0.431565\teval-mae:0.441542\n",
      "[41]\ttrain-mae:0.42917\teval-mae:0.439341\n",
      "[42]\ttrain-mae:0.427284\teval-mae:0.437694\n",
      "[43]\ttrain-mae:0.425639\teval-mae:0.436241\n",
      "[44]\ttrain-mae:0.424236\teval-mae:0.435025\n",
      "[45]\ttrain-mae:0.422954\teval-mae:0.433957\n",
      "[46]\ttrain-mae:0.421603\teval-mae:0.432762\n",
      "[47]\ttrain-mae:0.420628\teval-mae:0.432029\n",
      "[48]\ttrain-mae:0.419745\teval-mae:0.431324\n",
      "[49]\ttrain-mae:0.418955\teval-mae:0.430705\n",
      "[50]\ttrain-mae:0.418081\teval-mae:0.430004\n",
      "[51]\ttrain-mae:0.417314\teval-mae:0.429423\n",
      "[52]\ttrain-mae:0.416671\teval-mae:0.42894\n",
      "[53]\ttrain-mae:0.416134\teval-mae:0.428569\n",
      "[54]\ttrain-mae:0.41544\teval-mae:0.42807\n",
      "[55]\ttrain-mae:0.414905\teval-mae:0.427704\n",
      "[56]\ttrain-mae:0.414396\teval-mae:0.42733\n",
      "[57]\ttrain-mae:0.413907\teval-mae:0.426998\n",
      "[58]\ttrain-mae:0.413405\teval-mae:0.426754\n",
      "[59]\ttrain-mae:0.412856\teval-mae:0.426372\n",
      "[60]\ttrain-mae:0.412528\teval-mae:0.426169\n",
      "[61]\ttrain-mae:0.41214\teval-mae:0.42591\n",
      "[62]\ttrain-mae:0.411706\teval-mae:0.425582\n",
      "[63]\ttrain-mae:0.411191\teval-mae:0.425181\n",
      "[64]\ttrain-mae:0.410924\teval-mae:0.425027\n",
      "[65]\ttrain-mae:0.410605\teval-mae:0.424843\n",
      "[66]\ttrain-mae:0.410333\teval-mae:0.424735\n",
      "[67]\ttrain-mae:0.410078\teval-mae:0.424604\n",
      "[68]\ttrain-mae:0.409795\teval-mae:0.424476\n",
      "[69]\ttrain-mae:0.409527\teval-mae:0.424353\n",
      "[70]\ttrain-mae:0.409141\teval-mae:0.424133\n",
      "[71]\ttrain-mae:0.408863\teval-mae:0.424052\n",
      "[72]\ttrain-mae:0.40858\teval-mae:0.423988\n",
      "[73]\ttrain-mae:0.408283\teval-mae:0.423894\n",
      "[74]\ttrain-mae:0.407972\teval-mae:0.423746\n",
      "[75]\ttrain-mae:0.407743\teval-mae:0.423622\n",
      "[76]\ttrain-mae:0.407491\teval-mae:0.423508\n",
      "[77]\ttrain-mae:0.407236\teval-mae:0.423406\n",
      "[78]\ttrain-mae:0.406951\teval-mae:0.423262\n",
      "[79]\ttrain-mae:0.40669\teval-mae:0.423141\n",
      "[80]\ttrain-mae:0.406523\teval-mae:0.423099\n",
      "[81]\ttrain-mae:0.406241\teval-mae:0.422963\n",
      "[82]\ttrain-mae:0.405934\teval-mae:0.422868\n",
      "[83]\ttrain-mae:0.40558\teval-mae:0.422648\n",
      "[84]\ttrain-mae:0.405408\teval-mae:0.422602\n",
      "[85]\ttrain-mae:0.40509\teval-mae:0.422471\n",
      "[86]\ttrain-mae:0.404817\teval-mae:0.422359\n",
      "[87]\ttrain-mae:0.404616\teval-mae:0.422258\n",
      "[88]\ttrain-mae:0.40441\teval-mae:0.422192\n",
      "[89]\ttrain-mae:0.404148\teval-mae:0.422084\n",
      "[90]\ttrain-mae:0.403998\teval-mae:0.422034\n",
      "[91]\ttrain-mae:0.403821\teval-mae:0.421963\n",
      "[92]\ttrain-mae:0.4036\teval-mae:0.421815\n",
      "[93]\ttrain-mae:0.403438\teval-mae:0.421765\n",
      "[94]\ttrain-mae:0.403265\teval-mae:0.42167\n",
      "[95]\ttrain-mae:0.403022\teval-mae:0.421595\n",
      "[96]\ttrain-mae:0.402843\teval-mae:0.421521\n",
      "[97]\ttrain-mae:0.402737\teval-mae:0.421473\n",
      "[98]\ttrain-mae:0.402529\teval-mae:0.421384\n",
      "[99]\ttrain-mae:0.402327\teval-mae:0.421259\n",
      "[100]\ttrain-mae:0.402079\teval-mae:0.421166\n",
      "[101]\ttrain-mae:0.401862\teval-mae:0.421108\n",
      "[102]\ttrain-mae:0.401679\teval-mae:0.421001\n",
      "[103]\ttrain-mae:0.401572\teval-mae:0.420942\n",
      "[104]\ttrain-mae:0.401415\teval-mae:0.420922\n",
      "[105]\ttrain-mae:0.401212\teval-mae:0.420897\n",
      "[106]\ttrain-mae:0.401079\teval-mae:0.420852\n",
      "[107]\ttrain-mae:0.400986\teval-mae:0.420852\n",
      "[108]\ttrain-mae:0.40083\teval-mae:0.420822\n",
      "[109]\ttrain-mae:0.400588\teval-mae:0.420759\n",
      "[110]\ttrain-mae:0.400333\teval-mae:0.420685\n",
      "[111]\ttrain-mae:0.4002\teval-mae:0.420663\n",
      "[112]\ttrain-mae:0.399998\teval-mae:0.420619\n",
      "[113]\ttrain-mae:0.399819\teval-mae:0.420592\n",
      "[114]\ttrain-mae:0.39967\teval-mae:0.420538\n",
      "[115]\ttrain-mae:0.39958\teval-mae:0.420528\n",
      "[116]\ttrain-mae:0.399358\teval-mae:0.420495\n",
      "[117]\ttrain-mae:0.399252\teval-mae:0.420461\n",
      "[118]\ttrain-mae:0.399138\teval-mae:0.420424\n",
      "[119]\ttrain-mae:0.399008\teval-mae:0.420346\n",
      "[120]\ttrain-mae:0.398865\teval-mae:0.420286\n",
      "[121]\ttrain-mae:0.398729\teval-mae:0.42024\n",
      "[122]\ttrain-mae:0.398671\teval-mae:0.420229\n",
      "[123]\ttrain-mae:0.398564\teval-mae:0.420205\n",
      "[124]\ttrain-mae:0.398391\teval-mae:0.420156\n",
      "[125]\ttrain-mae:0.398167\teval-mae:0.420056\n",
      "[126]\ttrain-mae:0.398014\teval-mae:0.420057\n",
      "[127]\ttrain-mae:0.397902\teval-mae:0.420008\n",
      "[128]\ttrain-mae:0.397767\teval-mae:0.41998\n",
      "[129]\ttrain-mae:0.397634\teval-mae:0.419927\n",
      "[130]\ttrain-mae:0.397575\teval-mae:0.419893\n",
      "[131]\ttrain-mae:0.397406\teval-mae:0.419843\n",
      "[132]\ttrain-mae:0.39725\teval-mae:0.419814\n",
      "[133]\ttrain-mae:0.397058\teval-mae:0.419781\n",
      "[134]\ttrain-mae:0.396829\teval-mae:0.419712\n",
      "[135]\ttrain-mae:0.396672\teval-mae:0.419685\n",
      "[136]\ttrain-mae:0.396511\teval-mae:0.419675\n",
      "[137]\ttrain-mae:0.396447\teval-mae:0.419669\n",
      "[138]\ttrain-mae:0.396305\teval-mae:0.419623\n",
      "[139]\ttrain-mae:0.396132\teval-mae:0.41954\n",
      "[140]\ttrain-mae:0.396031\teval-mae:0.419544\n",
      "[141]\ttrain-mae:0.395945\teval-mae:0.419528\n",
      "[142]\ttrain-mae:0.395794\teval-mae:0.41948\n",
      "[143]\ttrain-mae:0.395576\teval-mae:0.419446\n",
      "[144]\ttrain-mae:0.395501\teval-mae:0.419418\n",
      "[145]\ttrain-mae:0.395367\teval-mae:0.41935\n",
      "[146]\ttrain-mae:0.395271\teval-mae:0.419347\n",
      "[147]\ttrain-mae:0.39513\teval-mae:0.419317\n",
      "[148]\ttrain-mae:0.395027\teval-mae:0.419256\n",
      "[149]\ttrain-mae:0.394845\teval-mae:0.419218\n",
      "[150]\ttrain-mae:0.394765\teval-mae:0.419232\n",
      "[151]\ttrain-mae:0.394639\teval-mae:0.419209\n",
      "[152]\ttrain-mae:0.394535\teval-mae:0.419208\n",
      "[153]\ttrain-mae:0.394451\teval-mae:0.419192\n",
      "[154]\ttrain-mae:0.39436\teval-mae:0.419179\n",
      "[155]\ttrain-mae:0.394344\teval-mae:0.419182\n",
      "[156]\ttrain-mae:0.394125\teval-mae:0.419131\n",
      "[157]\ttrain-mae:0.393989\teval-mae:0.419099\n",
      "[158]\ttrain-mae:0.393835\teval-mae:0.419058\n",
      "[159]\ttrain-mae:0.393751\teval-mae:0.419055\n",
      "[160]\ttrain-mae:0.393555\teval-mae:0.41899\n",
      "[161]\ttrain-mae:0.393427\teval-mae:0.418962\n",
      "[162]\ttrain-mae:0.393303\teval-mae:0.418971\n",
      "[163]\ttrain-mae:0.393137\teval-mae:0.418975\n",
      "[164]\ttrain-mae:0.39305\teval-mae:0.418977\n",
      "[165]\ttrain-mae:0.392922\teval-mae:0.418947\n",
      "[166]\ttrain-mae:0.392897\teval-mae:0.418955\n",
      "[167]\ttrain-mae:0.392829\teval-mae:0.41896\n",
      "[168]\ttrain-mae:0.392658\teval-mae:0.418931\n",
      "[169]\ttrain-mae:0.392513\teval-mae:0.418865\n",
      "[170]\ttrain-mae:0.392359\teval-mae:0.418837\n",
      "[171]\ttrain-mae:0.392268\teval-mae:0.418855\n",
      "[172]\ttrain-mae:0.392163\teval-mae:0.418825\n",
      "[173]\ttrain-mae:0.392046\teval-mae:0.41882\n",
      "[174]\ttrain-mae:0.391912\teval-mae:0.418801\n",
      "[175]\ttrain-mae:0.391751\teval-mae:0.418732\n",
      "[176]\ttrain-mae:0.39158\teval-mae:0.418728\n",
      "[177]\ttrain-mae:0.391484\teval-mae:0.418699\n",
      "[178]\ttrain-mae:0.391293\teval-mae:0.418697\n",
      "[179]\ttrain-mae:0.391186\teval-mae:0.418684\n",
      "[180]\ttrain-mae:0.391092\teval-mae:0.418665\n",
      "[181]\ttrain-mae:0.390924\teval-mae:0.418644\n",
      "[182]\ttrain-mae:0.390709\teval-mae:0.418589\n",
      "[183]\ttrain-mae:0.390581\teval-mae:0.41856\n",
      "[184]\ttrain-mae:0.390515\teval-mae:0.418566\n",
      "[185]\ttrain-mae:0.390435\teval-mae:0.418566\n",
      "[186]\ttrain-mae:0.390393\teval-mae:0.418566\n",
      "[187]\ttrain-mae:0.39031\teval-mae:0.418556\n",
      "[188]\ttrain-mae:0.390179\teval-mae:0.418554\n",
      "[189]\ttrain-mae:0.390035\teval-mae:0.418555\n",
      "[190]\ttrain-mae:0.389979\teval-mae:0.418557\n",
      "[191]\ttrain-mae:0.389947\teval-mae:0.418558\n",
      "[192]\ttrain-mae:0.389883\teval-mae:0.418551\n",
      "[193]\ttrain-mae:0.389838\teval-mae:0.418554\n",
      "[194]\ttrain-mae:0.389744\teval-mae:0.418574\n",
      "[195]\ttrain-mae:0.389618\teval-mae:0.418547\n",
      "[196]\ttrain-mae:0.389515\teval-mae:0.418534\n",
      "[197]\ttrain-mae:0.38944\teval-mae:0.418528\n",
      "[198]\ttrain-mae:0.389351\teval-mae:0.418513\n",
      "[199]\ttrain-mae:0.389256\teval-mae:0.418525\n",
      "[200]\ttrain-mae:0.38915\teval-mae:0.418539\n",
      "[201]\ttrain-mae:0.389013\teval-mae:0.418552\n",
      "[202]\ttrain-mae:0.388872\teval-mae:0.418524\n",
      "[203]\ttrain-mae:0.388632\teval-mae:0.418459\n",
      "[204]\ttrain-mae:0.388504\teval-mae:0.418431\n",
      "[205]\ttrain-mae:0.388387\teval-mae:0.41842\n",
      "[206]\ttrain-mae:0.388194\teval-mae:0.418435\n",
      "[207]\ttrain-mae:0.388115\teval-mae:0.41841\n",
      "[208]\ttrain-mae:0.387957\teval-mae:0.418382\n",
      "[209]\ttrain-mae:0.387769\teval-mae:0.418318\n",
      "[210]\ttrain-mae:0.387707\teval-mae:0.418317\n",
      "[211]\ttrain-mae:0.387617\teval-mae:0.418315\n",
      "[212]\ttrain-mae:0.387556\teval-mae:0.418315\n",
      "[213]\ttrain-mae:0.387497\teval-mae:0.418316\n",
      "[214]\ttrain-mae:0.387432\teval-mae:0.41832\n",
      "[215]\ttrain-mae:0.387299\teval-mae:0.418271\n",
      "[216]\ttrain-mae:0.38707\teval-mae:0.4182\n",
      "[217]\ttrain-mae:0.386929\teval-mae:0.418174\n",
      "[218]\ttrain-mae:0.386772\teval-mae:0.418184\n",
      "[219]\ttrain-mae:0.386723\teval-mae:0.418175\n",
      "[220]\ttrain-mae:0.386705\teval-mae:0.418167\n",
      "[221]\ttrain-mae:0.38656\teval-mae:0.418171\n",
      "[222]\ttrain-mae:0.38652\teval-mae:0.418166\n",
      "[223]\ttrain-mae:0.386368\teval-mae:0.418197\n",
      "[224]\ttrain-mae:0.386232\teval-mae:0.418166\n",
      "[225]\ttrain-mae:0.386154\teval-mae:0.418168\n",
      "[226]\ttrain-mae:0.386046\teval-mae:0.418151\n",
      "[227]\ttrain-mae:0.385988\teval-mae:0.418125\n",
      "[228]\ttrain-mae:0.385868\teval-mae:0.418132\n",
      "[229]\ttrain-mae:0.385769\teval-mae:0.418135\n",
      "[230]\ttrain-mae:0.385621\teval-mae:0.418126\n",
      "[231]\ttrain-mae:0.385506\teval-mae:0.418103\n",
      "[232]\ttrain-mae:0.385453\teval-mae:0.418084\n",
      "[233]\ttrain-mae:0.385394\teval-mae:0.418105\n",
      "[234]\ttrain-mae:0.385342\teval-mae:0.418112\n",
      "[235]\ttrain-mae:0.385169\teval-mae:0.4181\n",
      "[236]\ttrain-mae:0.385041\teval-mae:0.418078\n",
      "[237]\ttrain-mae:0.384923\teval-mae:0.418047\n",
      "[238]\ttrain-mae:0.38483\teval-mae:0.418032\n",
      "[239]\ttrain-mae:0.384766\teval-mae:0.418025\n",
      "[240]\ttrain-mae:0.384683\teval-mae:0.418018\n",
      "[241]\ttrain-mae:0.384584\teval-mae:0.418003\n",
      "[242]\ttrain-mae:0.384504\teval-mae:0.417968\n",
      "[243]\ttrain-mae:0.384417\teval-mae:0.417981\n",
      "[244]\ttrain-mae:0.384321\teval-mae:0.417996\n",
      "[245]\ttrain-mae:0.384246\teval-mae:0.417996\n",
      "[246]\ttrain-mae:0.384162\teval-mae:0.417993\n",
      "[247]\ttrain-mae:0.384058\teval-mae:0.418008\n",
      "[248]\ttrain-mae:0.383969\teval-mae:0.417986\n",
      "[249]\ttrain-mae:0.383845\teval-mae:0.417953\n",
      "[250]\ttrain-mae:0.38379\teval-mae:0.417959\n",
      "[251]\ttrain-mae:0.383654\teval-mae:0.417948\n",
      "[252]\ttrain-mae:0.383523\teval-mae:0.417927\n",
      "[253]\ttrain-mae:0.38339\teval-mae:0.417899\n",
      "[254]\ttrain-mae:0.383277\teval-mae:0.4179\n",
      "[255]\ttrain-mae:0.383245\teval-mae:0.417903\n",
      "[256]\ttrain-mae:0.383195\teval-mae:0.417909\n",
      "[257]\ttrain-mae:0.383073\teval-mae:0.417887\n",
      "[258]\ttrain-mae:0.383001\teval-mae:0.41789\n",
      "[259]\ttrain-mae:0.382917\teval-mae:0.417863\n",
      "[260]\ttrain-mae:0.382789\teval-mae:0.417849\n",
      "[261]\ttrain-mae:0.382601\teval-mae:0.417801\n",
      "[262]\ttrain-mae:0.382446\teval-mae:0.417765\n",
      "[263]\ttrain-mae:0.382339\teval-mae:0.417775\n",
      "[264]\ttrain-mae:0.382211\teval-mae:0.417797\n",
      "[265]\ttrain-mae:0.382051\teval-mae:0.417773\n",
      "[266]\ttrain-mae:0.38198\teval-mae:0.417783\n",
      "[267]\ttrain-mae:0.381882\teval-mae:0.417791\n",
      "[268]\ttrain-mae:0.38182\teval-mae:0.41781\n",
      "[269]\ttrain-mae:0.381733\teval-mae:0.417784\n",
      "[270]\ttrain-mae:0.381639\teval-mae:0.417773\n",
      "[271]\ttrain-mae:0.381519\teval-mae:0.417732\n",
      "[272]\ttrain-mae:0.381391\teval-mae:0.41774\n",
      "[273]\ttrain-mae:0.381325\teval-mae:0.417746\n",
      "[274]\ttrain-mae:0.381124\teval-mae:0.417747\n",
      "[275]\ttrain-mae:0.380986\teval-mae:0.417741\n",
      "[276]\ttrain-mae:0.380873\teval-mae:0.417735\n",
      "[277]\ttrain-mae:0.380792\teval-mae:0.417748\n",
      "[278]\ttrain-mae:0.380731\teval-mae:0.417741\n",
      "[279]\ttrain-mae:0.380626\teval-mae:0.417754\n",
      "[280]\ttrain-mae:0.380515\teval-mae:0.41774\n",
      "[281]\ttrain-mae:0.380372\teval-mae:0.417761\n",
      "[282]\ttrain-mae:0.38032\teval-mae:0.417765\n",
      "[283]\ttrain-mae:0.380288\teval-mae:0.417758\n",
      "[284]\ttrain-mae:0.380247\teval-mae:0.417772\n",
      "[285]\ttrain-mae:0.380096\teval-mae:0.417777\n",
      "[286]\ttrain-mae:0.379987\teval-mae:0.417791\n",
      "[287]\ttrain-mae:0.379893\teval-mae:0.417779\n",
      "[288]\ttrain-mae:0.379819\teval-mae:0.417773\n",
      "[289]\ttrain-mae:0.379747\teval-mae:0.417795\n",
      "[290]\ttrain-mae:0.379679\teval-mae:0.417792\n",
      "[291]\ttrain-mae:0.379643\teval-mae:0.417802\n",
      "Stopping. Best iteration:\n",
      "[271]\ttrain-mae:0.381519\teval-mae:0.417732\n",
      "\n",
      "('best ntree limit', 3, 272)\n",
      "('mae for part train', 3, 1034.1451240983342)\n",
      "('mae for part test', 3, 1151.0150668762383)\n",
      "('mae for all train', 3, 1057.5187402945778)\n",
      "[0]\ttrain-mae:6.46695\teval-mae:6.46693\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mae:5.82049\teval-mae:5.82036\n",
      "[2]\ttrain-mae:5.23874\teval-mae:5.23858\n",
      "[3]\ttrain-mae:4.71512\teval-mae:4.71501\n",
      "[4]\ttrain-mae:4.24384\teval-mae:4.2439\n",
      "[5]\ttrain-mae:3.8197\teval-mae:3.81988\n",
      "[6]\ttrain-mae:3.438\teval-mae:3.43828\n",
      "[7]\ttrain-mae:3.09453\teval-mae:3.09467\n",
      "[8]\ttrain-mae:2.78545\teval-mae:2.78578\n",
      "[9]\ttrain-mae:2.50735\teval-mae:2.50765\n",
      "[10]\ttrain-mae:2.25728\teval-mae:2.25752\n",
      "[11]\ttrain-mae:2.03249\teval-mae:2.03286\n",
      "[12]\ttrain-mae:1.83052\teval-mae:1.83113\n",
      "[13]\ttrain-mae:1.64941\teval-mae:1.6502\n",
      "[14]\ttrain-mae:1.48724\teval-mae:1.48822\n",
      "[15]\ttrain-mae:1.34248\teval-mae:1.3435\n",
      "[16]\ttrain-mae:1.21374\teval-mae:1.21487\n",
      "[17]\ttrain-mae:1.09997\teval-mae:1.10121\n",
      "[18]\ttrain-mae:0.99999\teval-mae:1.00138\n",
      "[19]\ttrain-mae:0.912649\teval-mae:0.914042\n",
      "[20]\ttrain-mae:0.83713\teval-mae:0.8388\n",
      "[21]\ttrain-mae:0.771962\teval-mae:0.773685\n",
      "[22]\ttrain-mae:0.716509\teval-mae:0.718381\n",
      "[23]\ttrain-mae:0.669237\teval-mae:0.671338\n",
      "[24]\ttrain-mae:0.629251\teval-mae:0.631623\n",
      "[25]\ttrain-mae:0.59551\teval-mae:0.598074\n",
      "[26]\ttrain-mae:0.567232\teval-mae:0.570029\n",
      "[27]\ttrain-mae:0.543421\teval-mae:0.54646\n",
      "[28]\ttrain-mae:0.523099\teval-mae:0.526094\n",
      "[29]\ttrain-mae:0.506317\teval-mae:0.509412\n",
      "[30]\ttrain-mae:0.492512\teval-mae:0.49583\n",
      "[31]\ttrain-mae:0.480713\teval-mae:0.484186\n",
      "[32]\ttrain-mae:0.471025\teval-mae:0.474768\n",
      "[33]\ttrain-mae:0.462781\teval-mae:0.466635\n",
      "[34]\ttrain-mae:0.456055\teval-mae:0.460084\n",
      "[35]\ttrain-mae:0.450347\teval-mae:0.454623\n",
      "[36]\ttrain-mae:0.4453\teval-mae:0.449698\n",
      "[37]\ttrain-mae:0.441223\teval-mae:0.445768\n",
      "[38]\ttrain-mae:0.437781\teval-mae:0.44252\n",
      "[39]\ttrain-mae:0.434602\teval-mae:0.43953\n",
      "[40]\ttrain-mae:0.432005\teval-mae:0.437162\n",
      "[41]\ttrain-mae:0.429917\teval-mae:0.435221\n",
      "[42]\ttrain-mae:0.427898\teval-mae:0.433429\n",
      "[43]\ttrain-mae:0.426249\teval-mae:0.431972\n",
      "[44]\ttrain-mae:0.424756\teval-mae:0.430636\n",
      "[45]\ttrain-mae:0.423567\teval-mae:0.429593\n",
      "[46]\ttrain-mae:0.422414\teval-mae:0.428599\n",
      "[47]\ttrain-mae:0.421474\teval-mae:0.427848\n",
      "[48]\ttrain-mae:0.420406\teval-mae:0.426998\n",
      "[49]\ttrain-mae:0.419442\teval-mae:0.426161\n",
      "[50]\ttrain-mae:0.418685\teval-mae:0.425483\n",
      "[51]\ttrain-mae:0.418\teval-mae:0.425017\n",
      "[52]\ttrain-mae:0.417399\teval-mae:0.424573\n",
      "[53]\ttrain-mae:0.416688\teval-mae:0.424048\n",
      "[54]\ttrain-mae:0.416164\teval-mae:0.423737\n",
      "[55]\ttrain-mae:0.415668\teval-mae:0.42336\n",
      "[56]\ttrain-mae:0.415196\teval-mae:0.423001\n",
      "[57]\ttrain-mae:0.414629\teval-mae:0.422575\n",
      "[58]\ttrain-mae:0.414077\teval-mae:0.42221\n",
      "[59]\ttrain-mae:0.413712\teval-mae:0.422016\n",
      "[60]\ttrain-mae:0.413132\teval-mae:0.421588\n",
      "[61]\ttrain-mae:0.412647\teval-mae:0.42127\n",
      "[62]\ttrain-mae:0.412335\teval-mae:0.421069\n",
      "[63]\ttrain-mae:0.412041\teval-mae:0.420909\n",
      "[64]\ttrain-mae:0.41171\teval-mae:0.420692\n",
      "[65]\ttrain-mae:0.411421\teval-mae:0.420596\n",
      "[66]\ttrain-mae:0.410959\teval-mae:0.420353\n",
      "[67]\ttrain-mae:0.410703\teval-mae:0.420257\n",
      "[68]\ttrain-mae:0.410457\teval-mae:0.42011\n",
      "[69]\ttrain-mae:0.410144\teval-mae:0.41995\n",
      "[70]\ttrain-mae:0.409904\teval-mae:0.419832\n",
      "[71]\ttrain-mae:0.409678\teval-mae:0.419741\n",
      "[72]\ttrain-mae:0.409228\teval-mae:0.419431\n",
      "[73]\ttrain-mae:0.408998\teval-mae:0.419306\n",
      "[74]\ttrain-mae:0.408744\teval-mae:0.419192\n",
      "[75]\ttrain-mae:0.408516\teval-mae:0.419056\n",
      "[76]\ttrain-mae:0.408246\teval-mae:0.418945\n",
      "[77]\ttrain-mae:0.408031\teval-mae:0.418848\n",
      "[78]\ttrain-mae:0.407734\teval-mae:0.418664\n",
      "[79]\ttrain-mae:0.407515\teval-mae:0.418564\n",
      "[80]\ttrain-mae:0.407261\teval-mae:0.418397\n",
      "[81]\ttrain-mae:0.406977\teval-mae:0.418272\n",
      "[82]\ttrain-mae:0.406785\teval-mae:0.418241\n",
      "[83]\ttrain-mae:0.406491\teval-mae:0.41811\n",
      "[84]\ttrain-mae:0.406154\teval-mae:0.417973\n",
      "[85]\ttrain-mae:0.405842\teval-mae:0.417818\n",
      "[86]\ttrain-mae:0.405628\teval-mae:0.417711\n",
      "[87]\ttrain-mae:0.405445\teval-mae:0.41762\n",
      "[88]\ttrain-mae:0.405263\teval-mae:0.417595\n",
      "[89]\ttrain-mae:0.405033\teval-mae:0.417535\n",
      "[90]\ttrain-mae:0.404907\teval-mae:0.417487\n",
      "[91]\ttrain-mae:0.404767\teval-mae:0.417465\n",
      "[92]\ttrain-mae:0.404571\teval-mae:0.417416\n",
      "[93]\ttrain-mae:0.404418\teval-mae:0.417363\n",
      "[94]\ttrain-mae:0.404139\teval-mae:0.41722\n",
      "[95]\ttrain-mae:0.403968\teval-mae:0.417113\n",
      "[96]\ttrain-mae:0.403642\teval-mae:0.416935\n",
      "[97]\ttrain-mae:0.40341\teval-mae:0.416871\n",
      "[98]\ttrain-mae:0.403261\teval-mae:0.416779\n",
      "[99]\ttrain-mae:0.403101\teval-mae:0.416732\n",
      "[100]\ttrain-mae:0.402914\teval-mae:0.416661\n",
      "[101]\ttrain-mae:0.402752\teval-mae:0.416621\n",
      "[102]\ttrain-mae:0.402568\teval-mae:0.416573\n",
      "[103]\ttrain-mae:0.402384\teval-mae:0.41655\n",
      "[104]\ttrain-mae:0.40228\teval-mae:0.416555\n",
      "[105]\ttrain-mae:0.402016\teval-mae:0.416433\n",
      "[106]\ttrain-mae:0.401708\teval-mae:0.4163\n",
      "[107]\ttrain-mae:0.401578\teval-mae:0.416262\n",
      "[108]\ttrain-mae:0.401438\teval-mae:0.416204\n",
      "[109]\ttrain-mae:0.401252\teval-mae:0.416149\n",
      "[110]\ttrain-mae:0.401044\teval-mae:0.416056\n",
      "[111]\ttrain-mae:0.400851\teval-mae:0.416009\n",
      "[112]\ttrain-mae:0.400624\teval-mae:0.415938\n",
      "[113]\ttrain-mae:0.400448\teval-mae:0.415918\n",
      "[114]\ttrain-mae:0.400228\teval-mae:0.415838\n",
      "[115]\ttrain-mae:0.400066\teval-mae:0.415788\n",
      "[116]\ttrain-mae:0.39992\teval-mae:0.415744\n",
      "[117]\ttrain-mae:0.399795\teval-mae:0.415686\n",
      "[118]\ttrain-mae:0.399659\teval-mae:0.415649\n",
      "[119]\ttrain-mae:0.399582\teval-mae:0.415622\n",
      "[120]\ttrain-mae:0.399439\teval-mae:0.415538\n",
      "[121]\ttrain-mae:0.399256\teval-mae:0.415478\n",
      "[122]\ttrain-mae:0.39904\teval-mae:0.415419\n",
      "[123]\ttrain-mae:0.398815\teval-mae:0.415328\n",
      "[124]\ttrain-mae:0.398649\teval-mae:0.415262\n",
      "[125]\ttrain-mae:0.398543\teval-mae:0.415253\n",
      "[126]\ttrain-mae:0.398305\teval-mae:0.415195\n",
      "[127]\ttrain-mae:0.398115\teval-mae:0.415122\n",
      "[128]\ttrain-mae:0.397933\teval-mae:0.415103\n",
      "[129]\ttrain-mae:0.397724\teval-mae:0.415054\n",
      "[130]\ttrain-mae:0.397575\teval-mae:0.414991\n",
      "[131]\ttrain-mae:0.39739\teval-mae:0.414896\n",
      "[132]\ttrain-mae:0.397237\teval-mae:0.414885\n",
      "[133]\ttrain-mae:0.39702\teval-mae:0.414818\n",
      "[134]\ttrain-mae:0.3969\teval-mae:0.414817\n",
      "[135]\ttrain-mae:0.396655\teval-mae:0.414736\n",
      "[136]\ttrain-mae:0.396455\teval-mae:0.414684\n",
      "[137]\ttrain-mae:0.396336\teval-mae:0.414646\n",
      "[138]\ttrain-mae:0.396158\teval-mae:0.41461\n",
      "[139]\ttrain-mae:0.396003\teval-mae:0.414588\n",
      "[140]\ttrain-mae:0.395851\teval-mae:0.414546\n",
      "[141]\ttrain-mae:0.395779\teval-mae:0.414541\n",
      "[142]\ttrain-mae:0.395649\teval-mae:0.41453\n",
      "[143]\ttrain-mae:0.395466\teval-mae:0.414462\n",
      "[144]\ttrain-mae:0.39539\teval-mae:0.414442\n",
      "[145]\ttrain-mae:0.395233\teval-mae:0.414374\n",
      "[146]\ttrain-mae:0.395146\teval-mae:0.414359\n",
      "[147]\ttrain-mae:0.395004\teval-mae:0.414314\n",
      "[148]\ttrain-mae:0.394796\teval-mae:0.414263\n",
      "[149]\ttrain-mae:0.394609\teval-mae:0.414221\n",
      "[150]\ttrain-mae:0.394516\teval-mae:0.414205\n",
      "[151]\ttrain-mae:0.394417\teval-mae:0.414192\n",
      "[152]\ttrain-mae:0.394287\teval-mae:0.414142\n",
      "[153]\ttrain-mae:0.394139\teval-mae:0.414086\n",
      "[154]\ttrain-mae:0.394044\teval-mae:0.414062\n",
      "[155]\ttrain-mae:0.393937\teval-mae:0.414015\n",
      "[156]\ttrain-mae:0.393779\teval-mae:0.414006\n",
      "[157]\ttrain-mae:0.3937\teval-mae:0.41399\n",
      "[158]\ttrain-mae:0.393602\teval-mae:0.413989\n",
      "[159]\ttrain-mae:0.393448\teval-mae:0.414005\n",
      "[160]\ttrain-mae:0.39322\teval-mae:0.413959\n",
      "[161]\ttrain-mae:0.393065\teval-mae:0.413936\n",
      "[162]\ttrain-mae:0.392986\teval-mae:0.413915\n",
      "[163]\ttrain-mae:0.392869\teval-mae:0.413903\n",
      "[164]\ttrain-mae:0.392763\teval-mae:0.413884\n",
      "[165]\ttrain-mae:0.392693\teval-mae:0.413832\n",
      "[166]\ttrain-mae:0.392604\teval-mae:0.413813\n",
      "[167]\ttrain-mae:0.392525\teval-mae:0.41382\n",
      "[168]\ttrain-mae:0.392373\teval-mae:0.413809\n",
      "[169]\ttrain-mae:0.392249\teval-mae:0.41378\n",
      "[170]\ttrain-mae:0.392173\teval-mae:0.413771\n",
      "[171]\ttrain-mae:0.3921\teval-mae:0.413784\n",
      "[172]\ttrain-mae:0.391872\teval-mae:0.413704\n",
      "[173]\ttrain-mae:0.391788\teval-mae:0.413685\n",
      "[174]\ttrain-mae:0.391569\teval-mae:0.413624\n",
      "[175]\ttrain-mae:0.391444\teval-mae:0.413607\n",
      "[176]\ttrain-mae:0.391313\teval-mae:0.413602\n",
      "[177]\ttrain-mae:0.391227\teval-mae:0.413593\n",
      "[178]\ttrain-mae:0.391147\teval-mae:0.413588\n",
      "[179]\ttrain-mae:0.391088\teval-mae:0.413569\n",
      "[180]\ttrain-mae:0.39089\teval-mae:0.413533\n",
      "[181]\ttrain-mae:0.390721\teval-mae:0.413518\n",
      "[182]\ttrain-mae:0.390657\teval-mae:0.413522\n",
      "[183]\ttrain-mae:0.390544\teval-mae:0.413521\n",
      "[184]\ttrain-mae:0.390449\teval-mae:0.413512\n",
      "[185]\ttrain-mae:0.390392\teval-mae:0.41352\n",
      "[186]\ttrain-mae:0.390335\teval-mae:0.413529\n",
      "[187]\ttrain-mae:0.390172\teval-mae:0.41352\n",
      "[188]\ttrain-mae:0.390055\teval-mae:0.413509\n",
      "[189]\ttrain-mae:0.390015\teval-mae:0.413498\n",
      "[190]\ttrain-mae:0.389824\teval-mae:0.413491\n",
      "[191]\ttrain-mae:0.38971\teval-mae:0.41349\n",
      "[192]\ttrain-mae:0.389585\teval-mae:0.413471\n",
      "[193]\ttrain-mae:0.389492\teval-mae:0.413446\n",
      "[194]\ttrain-mae:0.389381\teval-mae:0.413423\n",
      "[195]\ttrain-mae:0.389233\teval-mae:0.413426\n",
      "[196]\ttrain-mae:0.389067\teval-mae:0.413403\n",
      "[197]\ttrain-mae:0.388992\teval-mae:0.413389\n",
      "[198]\ttrain-mae:0.38881\teval-mae:0.413377\n",
      "[199]\ttrain-mae:0.388711\teval-mae:0.413386\n",
      "[200]\ttrain-mae:0.388587\teval-mae:0.413398\n",
      "[201]\ttrain-mae:0.388443\teval-mae:0.413372\n",
      "[202]\ttrain-mae:0.38836\teval-mae:0.413394\n",
      "[203]\ttrain-mae:0.388273\teval-mae:0.413373\n",
      "[204]\ttrain-mae:0.388203\teval-mae:0.413373\n",
      "[205]\ttrain-mae:0.388087\teval-mae:0.413346\n",
      "[206]\ttrain-mae:0.387974\teval-mae:0.413349\n",
      "[207]\ttrain-mae:0.387786\teval-mae:0.41334\n",
      "[208]\ttrain-mae:0.38771\teval-mae:0.413319\n",
      "[209]\ttrain-mae:0.387597\teval-mae:0.413285\n",
      "[210]\ttrain-mae:0.387405\teval-mae:0.413264\n",
      "[211]\ttrain-mae:0.38726\teval-mae:0.41325\n",
      "[212]\ttrain-mae:0.387126\teval-mae:0.413265\n",
      "[213]\ttrain-mae:0.387008\teval-mae:0.413239\n",
      "[214]\ttrain-mae:0.386897\teval-mae:0.41325\n",
      "[215]\ttrain-mae:0.386718\teval-mae:0.413248\n",
      "[216]\ttrain-mae:0.386685\teval-mae:0.413243\n",
      "[217]\ttrain-mae:0.386608\teval-mae:0.413206\n",
      "[218]\ttrain-mae:0.386469\teval-mae:0.4132\n",
      "[219]\ttrain-mae:0.386353\teval-mae:0.41319\n",
      "[220]\ttrain-mae:0.386192\teval-mae:0.413158\n",
      "[221]\ttrain-mae:0.386078\teval-mae:0.413159\n",
      "[222]\ttrain-mae:0.385977\teval-mae:0.413154\n",
      "[223]\ttrain-mae:0.38589\teval-mae:0.413139\n",
      "[224]\ttrain-mae:0.385856\teval-mae:0.41315\n",
      "[225]\ttrain-mae:0.385688\teval-mae:0.413107\n",
      "[226]\ttrain-mae:0.385531\teval-mae:0.413123\n",
      "[227]\ttrain-mae:0.385458\teval-mae:0.413123\n",
      "[228]\ttrain-mae:0.385349\teval-mae:0.413098\n",
      "[229]\ttrain-mae:0.385239\teval-mae:0.413104\n",
      "[230]\ttrain-mae:0.385077\teval-mae:0.413082\n",
      "[231]\ttrain-mae:0.384913\teval-mae:0.413086\n",
      "[232]\ttrain-mae:0.384752\teval-mae:0.413067\n",
      "[233]\ttrain-mae:0.384674\teval-mae:0.413079\n",
      "[234]\ttrain-mae:0.384619\teval-mae:0.413072\n",
      "[235]\ttrain-mae:0.384552\teval-mae:0.41306\n",
      "[236]\ttrain-mae:0.384484\teval-mae:0.413075\n",
      "[237]\ttrain-mae:0.384401\teval-mae:0.41309\n",
      "[238]\ttrain-mae:0.384258\teval-mae:0.413078\n",
      "[239]\ttrain-mae:0.384165\teval-mae:0.413054\n",
      "[240]\ttrain-mae:0.384027\teval-mae:0.41302\n",
      "[241]\ttrain-mae:0.383897\teval-mae:0.413022\n",
      "[242]\ttrain-mae:0.383721\teval-mae:0.413001\n",
      "[243]\ttrain-mae:0.383584\teval-mae:0.412994\n",
      "[244]\ttrain-mae:0.383507\teval-mae:0.412968\n",
      "[245]\ttrain-mae:0.38338\teval-mae:0.412983\n",
      "[246]\ttrain-mae:0.383223\teval-mae:0.412969\n",
      "[247]\ttrain-mae:0.383122\teval-mae:0.412966\n",
      "[248]\ttrain-mae:0.383079\teval-mae:0.412969\n",
      "[249]\ttrain-mae:0.383048\teval-mae:0.412965\n",
      "[250]\ttrain-mae:0.382901\teval-mae:0.41296\n",
      "[251]\ttrain-mae:0.382782\teval-mae:0.412952\n",
      "[252]\ttrain-mae:0.382718\teval-mae:0.412962\n",
      "[253]\ttrain-mae:0.382572\teval-mae:0.41295\n",
      "[254]\ttrain-mae:0.382564\teval-mae:0.412949\n",
      "[255]\ttrain-mae:0.382481\teval-mae:0.412965\n",
      "[256]\ttrain-mae:0.382295\teval-mae:0.412935\n",
      "[257]\ttrain-mae:0.382271\teval-mae:0.412933\n",
      "[258]\ttrain-mae:0.382215\teval-mae:0.412925\n",
      "[259]\ttrain-mae:0.382096\teval-mae:0.412914\n",
      "[260]\ttrain-mae:0.381931\teval-mae:0.412917\n",
      "[261]\ttrain-mae:0.381828\teval-mae:0.412926\n",
      "[262]\ttrain-mae:0.381722\teval-mae:0.412915\n",
      "[263]\ttrain-mae:0.381589\teval-mae:0.412893\n",
      "[264]\ttrain-mae:0.381532\teval-mae:0.412894\n",
      "[265]\ttrain-mae:0.381464\teval-mae:0.412901\n",
      "[266]\ttrain-mae:0.381393\teval-mae:0.4129\n",
      "[267]\ttrain-mae:0.381228\teval-mae:0.412897\n",
      "[268]\ttrain-mae:0.381097\teval-mae:0.412867\n",
      "[269]\ttrain-mae:0.381049\teval-mae:0.412852\n",
      "[270]\ttrain-mae:0.38096\teval-mae:0.412834\n",
      "[271]\ttrain-mae:0.380838\teval-mae:0.412843\n",
      "[272]\ttrain-mae:0.38064\teval-mae:0.412838\n",
      "[273]\ttrain-mae:0.38057\teval-mae:0.412838\n",
      "[274]\ttrain-mae:0.380402\teval-mae:0.412839\n",
      "[275]\ttrain-mae:0.380292\teval-mae:0.412848\n",
      "[276]\ttrain-mae:0.380275\teval-mae:0.412851\n",
      "[277]\ttrain-mae:0.380187\teval-mae:0.412844\n",
      "[278]\ttrain-mae:0.380117\teval-mae:0.412864\n",
      "[279]\ttrain-mae:0.380098\teval-mae:0.412871\n",
      "[280]\ttrain-mae:0.380022\teval-mae:0.412872\n",
      "[281]\ttrain-mae:0.37992\teval-mae:0.412871\n",
      "[282]\ttrain-mae:0.379828\teval-mae:0.412849\n",
      "[283]\ttrain-mae:0.379766\teval-mae:0.412829\n",
      "[284]\ttrain-mae:0.379699\teval-mae:0.412834\n",
      "[285]\ttrain-mae:0.379568\teval-mae:0.412811\n",
      "[286]\ttrain-mae:0.379477\teval-mae:0.41283\n",
      "[287]\ttrain-mae:0.37938\teval-mae:0.412799\n",
      "[288]\ttrain-mae:0.379252\teval-mae:0.4128\n",
      "[289]\ttrain-mae:0.379194\teval-mae:0.412786\n",
      "[290]\ttrain-mae:0.37911\teval-mae:0.412793\n",
      "[291]\ttrain-mae:0.378972\teval-mae:0.41278\n",
      "[292]\ttrain-mae:0.3789\teval-mae:0.412779\n",
      "[293]\ttrain-mae:0.378775\teval-mae:0.412723\n",
      "[294]\ttrain-mae:0.378662\teval-mae:0.412728\n",
      "[295]\ttrain-mae:0.378564\teval-mae:0.412721\n",
      "[296]\ttrain-mae:0.378493\teval-mae:0.412737\n",
      "[297]\ttrain-mae:0.378363\teval-mae:0.412731\n",
      "[298]\ttrain-mae:0.378172\teval-mae:0.412675\n",
      "[299]\ttrain-mae:0.378146\teval-mae:0.412677\n",
      "[300]\ttrain-mae:0.378022\teval-mae:0.412679\n",
      "[301]\ttrain-mae:0.377945\teval-mae:0.412693\n",
      "[302]\ttrain-mae:0.377899\teval-mae:0.412691\n",
      "[303]\ttrain-mae:0.37783\teval-mae:0.412695\n",
      "[304]\ttrain-mae:0.377747\teval-mae:0.412692\n",
      "[305]\ttrain-mae:0.377623\teval-mae:0.412693\n",
      "[306]\ttrain-mae:0.377564\teval-mae:0.412679\n",
      "[307]\ttrain-mae:0.37736\teval-mae:0.412701\n",
      "[308]\ttrain-mae:0.377213\teval-mae:0.412702\n",
      "[309]\ttrain-mae:0.377139\teval-mae:0.412699\n",
      "[310]\ttrain-mae:0.377028\teval-mae:0.412703\n",
      "[311]\ttrain-mae:0.376927\teval-mae:0.412703\n",
      "[312]\ttrain-mae:0.376777\teval-mae:0.412691\n",
      "[313]\ttrain-mae:0.376713\teval-mae:0.412693\n",
      "[314]\ttrain-mae:0.376609\teval-mae:0.412693\n",
      "[315]\ttrain-mae:0.37655\teval-mae:0.412705\n",
      "[316]\ttrain-mae:0.376504\teval-mae:0.412703\n",
      "[317]\ttrain-mae:0.376459\teval-mae:0.412695\n",
      "[318]\ttrain-mae:0.376387\teval-mae:0.412695\n",
      "Stopping. Best iteration:\n",
      "[298]\ttrain-mae:0.378172\teval-mae:0.412675\n",
      "\n",
      "('best ntree limit', 4, 299)\n",
      "('mae for part train', 4, 1022.7345460543079)\n",
      "('mae for part test', 4, 1136.6717914543558)\n",
      "('mae for all train', 4, 1045.5216321188479)\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "\n",
    "y_pred_train = np.zeros((train.shape[0], folds))\n",
    "y_pred = np.zeros((test.shape[0], folds))\n",
    "score = np.zeros(folds)\n",
    "\n",
    "kf = KFold(n_splits=folds)\n",
    "kf.split(train)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    train_pd_ind = train.index[train_index]\n",
    "    test_pd_ind = train.index[test_index]\n",
    "    train_part, test_part = train.ix[train_pd_ind], train.ix[test_pd_ind]\n",
    "    \n",
    "    dtrain_part = xgb.DMatrix(train_part.drop(\"loss\", 1), response[train_pd_ind])\n",
    "    dtest_part = xgb.DMatrix(test_part.drop(\"loss\", 1), response[test_pd_ind])\n",
    "    params['seed'] = i * 5 + 100\n",
    "    clf = xgb.train(params, dtrain_part, num_boost_round=500,\n",
    "                    evals=[(dtrain_part, \"train\"), (dtest_part, \"eval\")], early_stopping_rounds=20)\n",
    "    \n",
    "    #limit = clf.best_iteration + 1\n",
    "    limit = clf.best_ntree_limit\n",
    "    print(\"best ntree limit\", i, limit)\n",
    "    \n",
    "    this_pred_train = clf.predict(dtrain, ntree_limit=limit)\n",
    "    y_pred_train[:, i] = this_pred_train\n",
    "    \n",
    "    print(\"mae for part train\",i, mean_absolute_error(\n",
    "            train_part.loss, restore_pred(clf.predict(dtrain_part, ntree_limit=clf.best_ntree_limit))))\n",
    "    print(\"mae for part test\",i, mean_absolute_error(\n",
    "            test_part.loss, restore_pred(clf.predict(dtest_part, ntree_limit=clf.best_ntree_limit))))\n",
    "    \n",
    "    score[i] = mean_absolute_error(train.loss, restore_pred(this_pred_train))\n",
    "    print(\"mae for all train\", i, score[i])\n",
    "    \n",
    "    this_pred_test = clf.predict(dtest, ntree_limit=limit)\n",
    "    y_pred[:, i] = this_pred_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"mae final train\", mean_absolute_error(train.loss, np.mean(restore_pred(y_pred_train), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "result = pd.DataFrame({\"id\": test.index, \"loss\": np.mean(restore_pred(y_pred), axis=1)})\n",
    "result.to_csv(\"result{:%Y%m%d%H%-M}.csv\".format(datetime.datetime.now()), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGBRegressor and important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_reg = dict(params)\n",
    "params_reg.pop(\"eta\")\n",
    "params_reg.pop('eval_metric')\n",
    "params_reg.pop('lambda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = XGBRegressor(**params_reg)\n",
    "reg.fit(train.drop(\"loss\", 1), train.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_predprob = reg.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_booster = reg.booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(18, 5)\n",
    "feat_imp = pd.Series(reg.booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "important_features = list(feat_imp[feat_imp > 4].index)\n",
    "print(\"important features:\", important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain_imp = xgb.DMatrix(train[important_features], train.loss)\n",
    "cvresult = xgb.cv(params, dtrain_imp, nfold=4, num_boost_round=50)\n",
    "print(cvresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params2 = {'base_score': 0.1, 'colsample_bytree': 0.9,\n",
    " 'eta': 0.3,\n",
    " 'eval_metric': 'mae',\n",
    " 'max_depth': 7,\n",
    " 'min_child_weight': 3,\n",
    " 'n_estimators': 10,\n",
    " 'objective': 'reg:linear',\n",
    " 'seed': 1,\n",
    " 'silent': True}\n",
    "regb = xgb.train(params2, dtrain_imp, num_boost_round=50, evals=[(dtrain_imp, \"train\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator=reg, \n",
    " param_grid = param_test1, scoring='neg_mean_squared_error',n_jobs=4, iid=False, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch1.fit(train.drop(\"loss\", 1), train.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
